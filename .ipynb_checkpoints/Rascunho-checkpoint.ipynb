{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "pd.options.display.max_rows = 13\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "\n",
    "def cleanup(text):\n",
    "    import string\n",
    "    punctuation = '[!-.:?;]'\n",
    "    pattern = re.compile(punctuation)\n",
    "    text_subbed = re.sub(pattern, ' ', text)\n",
    "    return text_subbed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tesla_raw = pd.read_excel (r'Tesla.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tesla_Negative = Tesla_raw[Tesla_raw[\"Classificação\"] == 0]\n",
    "Tesla_Positive = Tesla_raw[Tesla_raw[\"Classificação\"] == 1]\n",
    "Tesla_NR = Tesla_raw[Tesla_raw[\"Classificação\"] == 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tesla_Negative[\"Treinamento\"];\n",
    "Tesla_Positive[\"Treinamento\"];\n",
    "Tesla_NR[\"Treinamento\"];\n",
    "Tesla_raw[\"Treinamento\"];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tweets_N_Text = \"\"\n",
    "for e in Tesla_Negative[\"Treinamento\"]:\n",
    "    Tweets_N_Text += e\n",
    "\n",
    "Tweets_P_Text = \"\"\n",
    "for e in Tesla_Positive[\"Treinamento\"]:\n",
    "    Tweets_P_Text += e\n",
    "\n",
    "Tweets_NR_Text = \"\"\n",
    "for e in Tesla_NR[\"Treinamento\"]:\n",
    "    Tweets_NR_Text += e\n",
    "\n",
    "Tweets_R_Text = \"\"\n",
    "for e in Tesla_raw[\"Treinamento\"]:\n",
    "    Tweets_R_Text += e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tweets_N_TextClean = cleanup(Tweets_N_Text.lower())\n",
    "Tweets_P_TextClean = cleanup(Tweets_P_Text.lower())\n",
    "Tweets_NR_TextClean = cleanup(Tweets_NR_Text.lower())\n",
    "Tweets_R_TextClean = cleanup(Tweets_R_Text.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ajusta_emoji (lista): \n",
    "    \n",
    "    emoji_raw = \"🏳 🏴 🏁 🚩 🎌 🌈 ❤ 🧡 💛 💚 💙 💜 🖤 💔 ❣ 💕 💞 💓 💗 💖 💘 💝 💟 ☮ ✝ ☪ 🕉 ☸ ✡ 🔯 🕎 ☯ ☦ 🛐 ⛎ ♈ ♉ ♊ ♋ ♌ ♍ ♎ ♏ ♐ ♑ ♒ ♓ 🆔 ⚛ ⚕ ☢ ☣ 📴 📳 🈶 🈚 🈸 🈺 🈷 ✴ 🆚 🉑 💮 🉐 ㊙ ㊗ 🈴 🈵 🈹 🈲 🅰 🅱 🆎 🆑 🅾 🆘 ⛔ 📛 🚫 ❌ ⭕ 💢 ♨ 🚷 🚯 🚳 🚱 🔞 📵 🚭 ❗ ❕ ❓ ❔ ‼ ⁉ 💯 🔅 🔆 🔱 ⚜ 〽 ⚠ 🚸 🔰 ♻ 🈯 💹 ❇ ✳ ❎ ✅ 💠 🌀 ➿ 🌐 Ⓜ 🏧 🚾 ♿ 🅿 🈳 🈂 🛂 🛃 🛄 🛅 🚰 🚹 ♂ 🚺 ♀ 🚼 🚻 🚮 🎦 📶 🈁 🆖 🆗 🆙 🆒 🆕 🆓 0⃣ 1⃣ 2⃣ 3⃣ 4⃣ 5⃣ 6⃣ 7⃣ 8⃣ 9⃣ 🔟 🔢 ▶ ⏸ ⏯ ⏹ ⏺ ⏏ ⏭ ⏮ ⏩ ⏪ 🔀 🔁 🔂 ◀ 🔼 🔽 ⏫ ⏬ ➡ ⬅ ⬆ ⬇ ↗ ↘ ↙ ↖ ↕ ↔ 🔄 ↪ ↩ 🔃 ⤴ ⤵ #⃣ *⃣ ℹ 🔤 🔡 🔠 🔣 🎵 🎶 〰 ➰ ✔ ➕ ➖ ➗ ✖ 💲 💱 🔚 🔙 🔛 🔝 🔜 ☑ 🔘 ⚪ ⚫ 🔴 🔵 🔸 🔹 🔶 🔷 🔺 ▪ ▫ ⬛ ⬜ 🔻 ◼ ◻ ◾ ◽ 🔲 🔳 🔈 🔉 🔊 🔇 📣 📢 🔔 🔕 🃏 🀄 ♠ ♣ ♥ ♦ 🎴 👁‍🗨 🗨 💭 🗯 💬 🕐 🕑 🕒 🕓 🕔 🕕 🕖 🕗 🕘 🕙 🕚 🕛 🕜 🕝 🕞 🕟 🕠 🕡 🕢 🕣 🕤 🕥 🕦 🕧 😀 😬 😁 😂 😃 😄 🤣 😅 😆 😇 😉 😊 🙂 🙃 ☺ 😋 😌 😍 😘 😗 😙 😚 🤪 😜 😝 😛 🤑 😎 🤓 🧐 🤠 🤗 🤡 😏 😶 😐 😑 😒 🙄 🤨 🤔 🤫 🤭 🤥 😳 😞 😟 😠 😡 🤬 😔 😕 🙁 ☹ 😣 😖 😫 😩 😤 😮 😱 😨 😰 😯 😦 😧 😢 😥 😪 🤤 😓 😭 🤩 😵 😲 🤯 🤐 😷 🤕 🤒 🤮 🤢 🤧 😴 💤 😈 👿 👹 👺 💩 👻 💀 ☠ 👽 🤖 🎃 😺 😸 😹 😻 😼 😽 🙀 😿 😾 👐 🤲 🙌 👏 🙏 🤝 👍 👎 👊 ✊ 🤛 🤜 🤞 ✌ 🤘 🤟 👌 👈 👉 👆 👇 ☝ ✋ 🤚 🖐 🖖 👋 🤙 💪 🖕 ✍ 🤳 💅 👄 👅 👂 👃 👁 👀 🧠 👤 👥 🗣 👶 🧒 👦 👧 🧑 👨 🧔 👱‍♂️ 👩 👱‍♀️ 🧓 👴 👵 👲 👳‍♀️ 👳‍♂️ 🧕 👮‍♀️ 👮‍♂️ 👩‍🚒 👨‍🚒 👷‍♀️ 👷‍♂️ 👩‍🏭 👨‍🏭 👩‍🔧 👨‍🔧 👩‍🌾 👨‍🌾 👩‍🍳 👨‍🍳 👩‍🎤 👨‍🎤 👩‍🎨 👨‍🎨 👩‍🏫 👨‍🏫 👩‍🎓 👨‍🎓 👩‍💼 👨‍💼 👩‍💻 👨‍💻 👩‍🔬 👨‍🔬 👩‍🚀 👨‍🚀 👩‍⚕️ 👨‍⚕️ 👩‍⚖️ 👨‍⚖️ 👩‍✈️ 👨‍✈️ 💂‍♀️ 💂‍♂️ 🕵️‍♀️ 🕵️‍♂️ 🤶 🎅 👼 👸 🤴 👰 🤵‍♀️ 🤵 🕴️‍♀️ 🕴 🧙‍♀️ 🧙‍♂️ 🧝‍♀️ 🧝‍♂️ 🧚‍♀️ 🧚‍♂️ 🧞‍♀️ 🧞‍♂️ 🧜‍♀️ 🧜‍♂️ 🧛‍♀️ 🧛‍♂️ 🧟‍♀️ 🧟‍♂️ 🙇‍♀️ 🙇‍♂️ 💁‍♀️ 💁‍♂️ 🙅‍♀️ 🙅‍♂️ 🙆‍♀️ 🙆‍♂️ 🤷‍♀️ 🤷‍♂️ 🙋‍♀️ 🙋‍♂️ 🤦‍♀️ 🤦‍♂️ 🙎‍♀️ 🙎‍♂️ 🙍‍♀️ 🙍‍♂️ 💇‍♀️ 💇‍♂️ 💆‍♀️ 💆‍♂️ 🤰 🤱 🚶‍♀️ 🚶‍♂️ 🏃‍♀️ 🏃‍♂️ 💃 🕺 👯‍♀️ 👯‍♂️ 👫 👬 👭 💑 👩‍❤️‍👩 👨‍❤️‍👨 💏 👩‍❤️‍💋‍👩 👨‍❤️‍💋‍👨 👪 👨‍👩‍👧 👨‍👩‍👧‍👦 👨‍👩‍👦‍👦 👨‍👩‍👧‍👧 👩‍👩‍👦 👩‍👩‍👧 👩‍👩‍👧‍👦 👩‍👩‍👦‍👦 👩‍👩‍👧‍👧 👨‍👨‍👦 👨‍👨‍👧 👨‍👨‍👧‍👦 👨‍👨‍👦‍👦 👨‍👨‍👧‍👧 👩‍👦 👩‍👧 👩‍👧‍👦 👩‍👦‍👦 👩‍👧‍👧 👨‍👦 👨‍👧 👨‍👧‍👦 👨‍👦‍👦 👨‍👧‍👧 👚 👕 🧥 👖 👔 👗 👙 👘 💄 💋 👣 🧦 👠 👡 👢 👞 👟 🧢 👒 🎩 🎓 👑 ⛑ 🎒 👝 👛 👜 💼 👓 🕶 🧣 🧤 💍 🌂 ☂ ⌚ 📱 📲 💻 ⌨ 🖥 🖨 🖱 🖲 🕹 🗜 💽 💾 💿 📀 📼 📷 📸 📹 🎥 📽 🎞 📞 ☎ 📟 📠 📺 📻 🎙 🎚 🎛 ⏱ ⏲ ⏰ 🕰 ⏳ ⌛ 📡 🔋 🔌 💡 🔦 🕯 🗑 🛢 🛒 💸 💵 💴 💶 💷 💰 💳 💎 ⚖ 🔧 🔨 ⚒ 🛠 ⛏ 🔩 ⚙ ⛓ 🔫 💣 🔪 🗡 ⚔ 🛡 🚬 ⚰ ⚱ 🏺 🔮 📿 💈 ⚗ 🔭 🔬 🕳 💊 💉 🌡 🏷 🔖 🚽 🚿 🛁 🛀 🔑 🗝 🛋 🛌 🛏 🚪 🛎 🖼 🗺 ⛱ 🗿 🛍 🎈 🎏 🎀 🎁 🎊 🎉 🎎 🎐 🏮 ✉ 📩 📨 📧 💌 📮 📪 📫 📬 📭 📦 📯 📥 📤 📜 📃 📑 📊 📈 📉 📄 📅 📆 🗓 📇 🗃 🗳 🗄 📋 🗒 📁 📂 🗂 🗞 📰 📓 📕 📗 📘 📙 📔 📒 📚 📖 🔗 📎 🖇 ✂ 📐 📏 📌 📍 🔐 🔒 🔓 🔏 🖊 🖋 ✒ 📝 ✏ 🖍 🖌 🔍 🔎 🚗 🚕 🚙 🚌 🚎 🏎 🚓 🚑 🚒 🚐 🚚 🚛 🚜 🏍 🛵 🚲 🛴 🚨 🚔 🚍 🚘 🚖 🚡 🚠 🚟 🚃 🚋 🚝 🚄 🚅 🚈 🚞 🚂 🚆 🚇 🚊 🚉 🚁 🛩 ✈ 🛫 🛬 🛶 ⛵ 🛥 🚤 ⛴ 🛳 🚀 🛸 🛰 💺 ⚓ 🚧 ⛽ 🚏 🚦 🚥 🛑 🚢 🎡 🎢 🎠 🏗 🌁 🗼 🏭 ⛲ 🎑 ⛰ 🏔 🗻 🌋 🗾 🏕 ⛺ 🏞 🛣 🛤 🌅 🌄 🏜 🏖 🏝 🌇 🌆 🏙 🌃 🌉 🌌 🌠 🎇 🎆 🌈 🏘 🏰 🏯 🏟 🗽 🏠 🏡 🏚 🏢 🏬 🏣 🏤 🏥 🏦 🏨 🏪 🏫 🏩 💒 🏛 ⛪ 🕌 🕍 🕋 ⛩\"\n",
    "    emoji = emoji_raw.split()\n",
    "   \n",
    "    lista_emoji = []\n",
    "    palavra_limpa = []\n",
    "    \n",
    "    for e in lista:\n",
    "        palavra = ''\n",
    "        for letra in e:\n",
    "            if letra in emoji:\n",
    "                lista_emoji.append(letra)\n",
    "            else:\n",
    "                palavra += letra\n",
    "        palavra_limpa.append(palavra)\n",
    "    Final = lista_emoji + palavra_limpa\n",
    "    return Final\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "serie_N = pd.Series(ajusta_emoji(Tweets_N_TextClean.split()))\n",
    "serie_P = pd.Series(ajusta_emoji(Tweets_P_TextClean.split()))\n",
    "serie_NR = pd.Series(ajusta_emoji(Tweets_NR_TextClean.split()))\n",
    "serie_R = pd.Series(ajusta_emoji(Tweets_R_TextClean.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabela_N = serie_N.value_counts()\n",
    "tabela_P = serie_P.value_counts()\n",
    "tabela_NR = serie_NR.value_counts()\n",
    "tabela_R = serie_R.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_total = tabela_N.sum()\n",
    "P_total = tabela_P.sum()\n",
    "NR_total = tabela_NR.sum()\n",
    "R_total = len(tabela_R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Laplace_smoothing (x, cat):\n",
    "   \n",
    "    if cat == 0:\n",
    "        if x in tabela_N:\n",
    "            return (tabela_N[x] + 1) / (N_total + R_total)\n",
    "        else:\n",
    "            return (1) / (N_total + R_total)\n",
    "        \n",
    "    if cat == 1:\n",
    "        if x in tabela_P:\n",
    "            return (tabela_P[x] + 1) / (P_total + R_total)\n",
    "        else:\n",
    "            return (1) / (P_total + R_total)\n",
    "        \n",
    "    if cat == 2:\n",
    "        if x in tabela_NR:\n",
    "            return (tabela_NR[x] + 1) / (NR_total + R_total)\n",
    "        else:\n",
    "            return (1) / (NR_total + R_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bayes (Tweet):\n",
    "   \n",
    "    P0l = []\n",
    "    P1l = []\n",
    "    P2l = []\n",
    "    P0 = 1\n",
    "    P1 = 1\n",
    "    P2 = 1\n",
    "    \n",
    "    for e in Tweet:\n",
    "        P0l.append(Laplace_smoothing(e,0))\n",
    "        P1l.append(Laplace_smoothing(e,1))\n",
    "        P2l.append(Laplace_smoothing(e,2))\n",
    "    \n",
    "    for e in P0l:\n",
    "        P0 *= e\n",
    "    \n",
    "    for e in P1l:\n",
    "        P1 *= e\n",
    "        \n",
    "    for e in P2l:\n",
    "        P2 *= e\n",
    "    \n",
    "    if P0 > P1 and P0 > P2:\n",
    "        return (0)\n",
    "    \n",
    "    elif P1 > P0 and P1 > P2:\n",
    "        return (1)\n",
    "    \n",
    "    else:\n",
    "        return(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aplica_algoritimo(Tweets):\n",
    "\n",
    "    Tweets_lista = []\n",
    "    Tweet_valor = []\n",
    "\n",
    "    for e in Tweets['Teste']:\n",
    "        Tweets_lista.append(cleanup(e.lower()))\n",
    "    \n",
    "    for e in Tweets_lista:\n",
    "        tweet_split = ajusta_emoji(e.split())\n",
    "        Tweet_valor.append(bayes(tweet_split))\n",
    "    \n",
    "    return Tweet_valor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Teste</th>\n",
       "      <th>Classificação</th>\n",
       "      <th>Classificação do Algoritimo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rt @williamsbob75: another day, another lawsui...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@tesla_truth wait!! they want me to give them ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@davinalexmma @motorcyclebum @tesla you can ge...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rt @melaynalokosky: \"the best service, of cour...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@evnewsdaily i'd happily give my money back to...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>rt @business: teslas have an autopilot functio...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>$tsla - statement of changes in beneficial own...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>rt @insideevs: here's why tesla's h2 2019 will...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>rt @djdura: is there a bug or an extra feature...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>i need that lambo urus in off white and a tesl...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Teste  Classificação  \\\n",
       "0  rt @williamsbob75: another day, another lawsui...              2   \n",
       "1  @tesla_truth wait!! they want me to give them ...              1   \n",
       "2  @davinalexmma @motorcyclebum @tesla you can ge...              1   \n",
       "3  rt @melaynalokosky: \"the best service, of cour...              0   \n",
       "4  @evnewsdaily i'd happily give my money back to...              0   \n",
       "5  rt @business: teslas have an autopilot functio...              0   \n",
       "6  $tsla - statement of changes in beneficial own...              2   \n",
       "7  rt @insideevs: here's why tesla's h2 2019 will...              1   \n",
       "8  rt @djdura: is there a bug or an extra feature...              0   \n",
       "9  i need that lambo urus in off white and a tesl...              1   \n",
       "\n",
       "   Classificação do Algoritimo  \n",
       "0                            0  \n",
       "1                            1  \n",
       "2                            2  \n",
       "3                            0  \n",
       "4                            2  \n",
       "5                            0  \n",
       "6                            1  \n",
       "7                            1  \n",
       "8                            1  \n",
       "9                            1  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Tweet_teste = pd.read_excel (r'Tesla.xlsx', sheet_name = 'Teste', index = False)\n",
    "resultado_teste = aplica_algoritimo(Tweet_teste)\n",
    "Tweet_teste[\"Classificação do Algoritimo\"] = resultado_teste\n",
    "Tweet_teste.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com stemming:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "NCP = (Tweets_N_TextClean.split())\n",
    "PCP = (Tweets_P_TextClean.split())\n",
    "NRCP = (Tweets_NR_TextClean.split())\n",
    "RCP = (Tweets_R_TextClean.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_N = []\n",
    "for e in NCP:\n",
    "    j = stemmer.stem(e)\n",
    "    lista_N.append(j)\n",
    "    \n",
    "\n",
    "lista_P = []\n",
    "for e in PCP:\n",
    "    j = stemmer.stem(e)\n",
    "    lista_P.append(j)\n",
    "\n",
    "\n",
    "lista_NR = []\n",
    "for e in NRCP:\n",
    "    j = stemmer.stem(e)\n",
    "    lista_NR.append(j)\n",
    "\n",
    "lista_R = []\n",
    "for e in RCP:\n",
    "    j = stemmer.stem(e)\n",
    "    lista_R.append(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "serie_NS = pd.Series(ajusta_emoji(lista_N))\n",
    "serie_PS = pd.Series(ajusta_emoji(lista_P))\n",
    "serie_NRS = pd.Series(ajusta_emoji(lista_NR))\n",
    "serie_RS = pd.Series(ajusta_emoji(lista_R))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabela_NS = serie_NS.value_counts()\n",
    "tabela_PS = serie_PS.value_counts()\n",
    "tabela_NRS = serie_NRS.value_counts()\n",
    "tabela_RS = serie_RS.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_totalS = tabela_NS.sum()\n",
    "P_totalS = tabela_PS.sum()\n",
    "NR_totalS = tabela_NRS.sum()\n",
    "R_totalS = len(tabela_RS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Laplace_smoothingS (x, cat):\n",
    "   \n",
    "    if cat == 0:\n",
    "        if x in tabela_NS:\n",
    "            return (tabela_NS[x] + 1) / (N_totalS + R_totalS)\n",
    "        else:\n",
    "            return (1) / (N_totalS + R_totalS)\n",
    "        \n",
    "    if cat == 1:\n",
    "        if x in tabela_PS:\n",
    "            return (tabela_PS[x] + 1) / (P_totalS + R_totalS)\n",
    "        else:\n",
    "            return (1) / (P_totalS + R_totalS)\n",
    "        \n",
    "    if cat == 2:\n",
    "        if x in tabela_NRS:\n",
    "            return (tabela_NRS[x] + 1) / (NR_totalS + R_totalS)\n",
    "        else:\n",
    "            return (1) / (NR_totalS + R_totalS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bayesS (Tweet):\n",
    "   \n",
    "    P0l = []\n",
    "    P1l = []\n",
    "    P2l = []\n",
    "    P0 = 1\n",
    "    P1 = 1\n",
    "    P2 = 1\n",
    "    \n",
    "    for e in Tweet:\n",
    "        P0l.append(Laplace_smoothingS(e,0))\n",
    "        P1l.append(Laplace_smoothingS(e,1))\n",
    "        P2l.append(Laplace_smoothingS(e,2))\n",
    "    \n",
    "    for e in P0l:\n",
    "        P0 *= e\n",
    "    \n",
    "    for e in P1l:\n",
    "        P1 *= e\n",
    "        \n",
    "    for e in P2l:\n",
    "        P2 *= e\n",
    "    \n",
    "    if P0 > P1 and P0 > P2:\n",
    "        return (0)\n",
    "    \n",
    "    elif P1 > P0 and P1 > P2:\n",
    "        return (1)\n",
    "    \n",
    "    else:\n",
    "        return(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aplica_algoritimoS(Tweets):\n",
    "    \n",
    "    Tweets_lista = []\n",
    "    Tweet_valor = []\n",
    "\n",
    "    for e in Tweets['Teste']:\n",
    "        Tweets_lista.append(stemmer.stem(cleanup(e.lower())))\n",
    "    \n",
    "    for e in Tweets_lista:\n",
    "        tweet_split = ajusta_emoji(e.split())\n",
    "        Tweet_valor.append(bayesS(tweet_split))\n",
    "    \n",
    "    return Tweet_valor\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Teste</th>\n",
       "      <th>Classificação</th>\n",
       "      <th>Classificação do Algoritimo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rt @williamsbob75: another day, another lawsui...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@tesla_truth wait!! they want me to give them ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@davinalexmma @motorcyclebum @tesla you can ge...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rt @melaynalokosky: \"the best service, of cour...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@evnewsdaily i'd happily give my money back to...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>rt @business: teslas have an autopilot functio...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>$tsla - statement of changes in beneficial own...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>rt @insideevs: here's why tesla's h2 2019 will...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>rt @djdura: is there a bug or an extra feature...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>i need that lambo urus in off white and a tesl...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Teste  Classificação  \\\n",
       "0  rt @williamsbob75: another day, another lawsui...              2   \n",
       "1  @tesla_truth wait!! they want me to give them ...              1   \n",
       "2  @davinalexmma @motorcyclebum @tesla you can ge...              1   \n",
       "3  rt @melaynalokosky: \"the best service, of cour...              0   \n",
       "4  @evnewsdaily i'd happily give my money back to...              0   \n",
       "5  rt @business: teslas have an autopilot functio...              0   \n",
       "6  $tsla - statement of changes in beneficial own...              2   \n",
       "7  rt @insideevs: here's why tesla's h2 2019 will...              1   \n",
       "8  rt @djdura: is there a bug or an extra feature...              0   \n",
       "9  i need that lambo urus in off white and a tesl...              1   \n",
       "\n",
       "   Classificação do Algoritimo  \n",
       "0                            2  \n",
       "1                            1  \n",
       "2                            2  \n",
       "3                            0  \n",
       "4                            2  \n",
       "5                            0  \n",
       "6                            1  \n",
       "7                            1  \n",
       "8                            0  \n",
       "9                            1  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Tweet_testeS = pd.read_excel (r'Tesla.xlsx', sheet_name = 'Teste', index = False)\n",
    "resultado_testeS = aplica_algoritimoS(Tweet_testeS)\n",
    "Tweet_testeS[\"Classificação do Algoritimo\"] = resultado_testeS\n",
    "Tweet_testeS.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparando:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_normAL = []\n",
    "for e in Tweet_teste['Classificação do Algoritimo']:\n",
    "             class_normAL.append(e)\n",
    "\n",
    "class_norm = []\n",
    "for e in Tweet_teste['Classificação']:\n",
    "             class_norm.append(e)\n",
    "            \n",
    "        \n",
    "    \n",
    "class_SAL = []\n",
    "for e in Tweet_testeS['Classificação do Algoritimo']:\n",
    "             class_SAL.append(e)\n",
    "\n",
    "class_S = []\n",
    "for e in Tweet_testeS['Classificação']:\n",
    "             class_S.append(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "175\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "e = 0\n",
    "while i < len(class_norm):\n",
    "    if class_normAL[i] == class_norm[i]:\n",
    "        e += 1\n",
    "    i += 1\n",
    "print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "175\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "e = 0\n",
    "while i < len(class_norm):\n",
    "    if class_SAL[i] == class_S[i]:\n",
    "        e += 1\n",
    "    i += 1\n",
    "print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "2 0 2\n",
      "8\n",
      "0 1 0\n",
      "11\n",
      "2 1 1\n",
      "16\n",
      "2 1 0\n",
      "18\n",
      "2 0 2\n",
      "20\n",
      "1 0 1\n",
      "27\n",
      "2 1 1\n",
      "32\n",
      "2 0 0\n",
      "36\n",
      "1 0 1\n",
      "38\n",
      "2 1 0\n",
      "51\n",
      "2 1 0\n",
      "57\n",
      "2 1 2\n",
      "58\n",
      "1 0 1\n",
      "65\n",
      "1 0 0\n",
      "66\n",
      "1 0 1\n",
      "68\n",
      "0 1 2\n",
      "69\n",
      "2 1 0\n",
      "83\n",
      "2 0 1\n",
      "87\n",
      "2 1 1\n",
      "89\n",
      "2 1 1\n",
      "96\n",
      "1 0 2\n",
      "98\n",
      "1 2 1\n",
      "102\n",
      "2 1 0\n",
      "104\n",
      "2 1 1\n",
      "108\n",
      "2 1 0\n",
      "110\n",
      "2 1 1\n",
      "113\n",
      "0 1 1\n",
      "115\n",
      "2 0 2\n",
      "117\n",
      "0 1 0\n",
      "133\n",
      "0 1 2\n",
      "136\n",
      "1 0 0\n",
      "138\n",
      "2 0 2\n",
      "139\n",
      "2 0 2\n",
      "143\n",
      "2 1 2\n",
      "147\n",
      "2 0 2\n",
      "152\n",
      "2 0 0\n",
      "166\n",
      "0 1 1\n",
      "167\n",
      "2 1 1\n",
      "169\n",
      "2 0 1\n",
      "173\n",
      "2 0 0\n",
      "177\n",
      "0 1 1\n",
      "196\n",
      "0 1 0\n",
      "197\n",
      "0 1 1\n",
      "201\n",
      "2 0 1\n",
      "204\n",
      "2 1 1\n",
      "225\n",
      "1 0 1\n",
      "236\n",
      "0 1 0\n",
      "242\n",
      "2 1 0\n",
      "246\n",
      "2 1 0\n",
      "247\n",
      "1 0 0\n",
      "266\n",
      "0 1 0\n",
      "267\n",
      "2 0 0\n",
      "269\n",
      "2 0 0\n",
      "275\n",
      "0 1 0\n",
      "54\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "e = 0\n",
    "while i < len(class_S):\n",
    "    if class_SAL[i] != class_normAL[i]:\n",
    "        e += 1\n",
    "        print(i)\n",
    "        print(class_SAL[i],class_normAL[i],class_norm[i] )\n",
    "    i += 1\n",
    "print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Melhora banco de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seleciona_errados (tabela):\n",
    "    i = 0\n",
    "    erros1 = []\n",
    "    erros2 = []\n",
    "    while i < len (tabela['Classificação']):\n",
    "        if tabela['Classificação'][i] != tabela['Classificação do Algoritimo'][i]:\n",
    "            erros1.append(tabela[\"Teste\"][i]) \n",
    "            erros2.append(tabela[\"Classificação\"][i])\n",
    "        i += 1\n",
    "    return erros1, erros2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"Teste.csv\", \"a\") as myfile:\n",
    "    for e in seleciona_errados (Tweet_testeS)[0]:\n",
    "        x = (e.encode(\"utf-8\"))\n",
    "        myfile.write(f\"{x}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os.path\n",
    "import pandas as pd\n",
    "import json\n",
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Treinamento</th>\n",
       "      <th>Classificação</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@davinalexmma @motorcyclebum @tesla you can ge...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@evnewsdaily i'd happily give my money back to...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>$tsla - statement of changes in beneficial own...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rt @bridieev: .@tesla #model3 sales in #austra...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://t.co/kux1s3jitt\\n\\nelectric ford f-150...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>rt @itshovah: this is the tesla winner.. nice....</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>@aggersv @jason @tesla yup. so you wouldn’t ha...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>@sensarpensar @tesla_truth they actually did t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>wow, i think i need to follow gerard detourbet...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>@mindstatex nobody sleeps like that and wakes ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>‘based on the results of ford’s study, there i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>@alterviggo @tesla @elonmusk i think what dies...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>125 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Treinamento  Classificação\n",
       "0    @davinalexmma @motorcyclebum @tesla you can ge...              1\n",
       "1    @evnewsdaily i'd happily give my money back to...              0\n",
       "2    $tsla - statement of changes in beneficial own...              2\n",
       "3    rt @bridieev: .@tesla #model3 sales in #austra...              1\n",
       "4    https://t.co/kux1s3jitt\\n\\nelectric ford f-150...              0\n",
       "5    rt @itshovah: this is the tesla winner.. nice....              1\n",
       "..                                                 ...            ...\n",
       "119  @aggersv @jason @tesla yup. so you wouldn’t ha...              0\n",
       "120  @sensarpensar @tesla_truth they actually did t...              1\n",
       "121  wow, i think i need to follow gerard detourbet...              2\n",
       "122  @mindstatex nobody sleeps like that and wakes ...              2\n",
       "123  ‘based on the results of ford’s study, there i...              1\n",
       "124  @alterviggo @tesla @elonmusk i think what dies...              1\n",
       "\n",
       "[125 rows x 2 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# intialise data of lists. \n",
    "data = {'Treinamento':seleciona_errados(Tweet_testeS)[0], 'Classificação':seleciona_errados(Tweet_testeS)[1]} \n",
    "  \n",
    "# Create DataFrame \n",
    "df = pd.DataFrame(data) \n",
    "  \n",
    "# Print the output. \n",
    "df \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "125"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(seleciona_errados(Tweet_testeS)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Verifica se o arquivo não existe para não substituir um conjunto pronto\n",
    "if not os.path.isfile('Teste.xlsx'):\n",
    "    \n",
    "    #Abre o arquivo para escrita\n",
    "    writer = pd.ExcelWriter('Teste.xlsx')\n",
    "\n",
    "    #divide o conjunto de mensagens em duas planilhas\n",
    "    dft = df\n",
    "    dft.to_excel(excel_writer = writer, sheet_name = 'Treinamento', index = False)\n",
    "    \n",
    "    #fecha o arquivo\n",
    "    writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can only concatenate list (not \"str\") to list",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\ops.py\u001b[0m in \u001b[0;36msafe_na_op\u001b[1;34m(lvalues, rvalues)\u001b[0m\n\u001b[0;32m   1528\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'ignore'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1529\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mna_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1530\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\ops.py\u001b[0m in \u001b[0;36mna_op\u001b[1;34m(x, y)\u001b[0m\n\u001b[0;32m   1504\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1505\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexpressions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr_rep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0meval_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1506\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\computation\\expressions.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(op, op_str, a, b, use_numexpr, **eval_kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0muse_numexpr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_evaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop_str\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0meval_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0m_evaluate_standard\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop_str\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\computation\\expressions.py\u001b[0m in \u001b[0;36m_evaluate_numexpr\u001b[1;34m(op, op_str, a, b, truediv, reversed, **eval_kwargs)\u001b[0m\n\u001b[0;32m    122\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 123\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_evaluate_standard\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop_str\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    124\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\computation\\expressions.py\u001b[0m in \u001b[0;36m_evaluate_standard\u001b[1;34m(op, op_str, a, b, **eval_kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'ignore'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 68\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     69\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\ops.py\u001b[0m in \u001b[0;36mradd\u001b[1;34m(left, right)\u001b[0m\n\u001b[0;32m    143\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mradd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mleft\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mright\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 144\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mright\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mleft\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    145\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (125,) (450,) ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-46-6b5c67fecbb6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# intialise data of lists.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'Treinamento'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mseleciona_errados\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTweet_testeS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mTesla_raw\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Treinamento\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Classificação'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mseleciona_errados\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTweet_testeS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mTesla_raw\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Classificação\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Create DataFrame\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\ops.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(left, right)\u001b[0m\n\u001b[0;32m   1581\u001b[0m             \u001b[0mrvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1582\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1583\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msafe_na_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1584\u001b[0m         return construct_result(left, result,\n\u001b[0;32m   1585\u001b[0m                                 index=left.index, name=res_name, dtype=None)\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\ops.py\u001b[0m in \u001b[0;36msafe_na_op\u001b[1;34m(lvalues, rvalues)\u001b[0m\n\u001b[0;32m   1531\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_object_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1532\u001b[0m                 return libalgos.arrmap_object(lvalues,\n\u001b[1;32m-> 1533\u001b[1;33m                                               lambda x: op(x, rvalues))\n\u001b[0m\u001b[0;32m   1534\u001b[0m             \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1535\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/algos.pyx\u001b[0m in \u001b[0;36mpandas._libs.algos.arrmap\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\ops.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m   1531\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_object_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1532\u001b[0m                 return libalgos.arrmap_object(lvalues,\n\u001b[1;32m-> 1533\u001b[1;33m                                               lambda x: op(x, rvalues))\n\u001b[0m\u001b[0;32m   1534\u001b[0m             \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1535\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\ops.py\u001b[0m in \u001b[0;36mradd\u001b[1;34m(left, right)\u001b[0m\n\u001b[0;32m    142\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    143\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mradd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mleft\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mright\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 144\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mright\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mleft\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    145\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    146\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: can only concatenate list (not \"str\") to list"
     ]
    }
   ],
   "source": [
    "# intialise data of lists. \n",
    "data = {'Treinamento':seleciona_errados(Tweet_testeS)[0] + Tesla_raw[\"Treinamento\"], 'Classificação':seleciona_errados(Tweet_testeS)[1] + Tesla_raw[\"Classificação\"]} \n",
    "  \n",
    "# Create DataFrame \n",
    "df = pd.DataFrame(data) \n",
    "  \n",
    "# Print the output. \n",
    "df \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isfile('Teste.xlsx'):\n",
    "    \n",
    "    #Abre o arquivo para escrita\n",
    "    writer = pd.ExcelWriter('Teste.xlsx')\n",
    "\n",
    "    #divide o conjunto de mensagens em duas planilhas\n",
    "    dft = df\n",
    "    dft.to_excel(excel_writer = writer, sheet_name = 'Treinamento', index = False)\n",
    "    \n",
    "    #fecha o arquivo\n",
    "    writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tesla_raw[\"Classificação\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tempo real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "#Instalando o tweepy\n",
    "!pip install tweepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import math\n",
    "import os.path\n",
    "import pandas as pd\n",
    "import json\n",
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dados de autenticação do twitter:\n",
    "\n",
    "#Coloque aqui o identificador da conta no twitter: @fulano\n",
    "\n",
    "#leitura do arquivo no formato JSON\n",
    "with open('auth.pass') as fp:    \n",
    "    data = json.load(fp)\n",
    "\n",
    "#Configurando a biblioteca. Não modificar\n",
    "auth = tweepy.OAuthHandler(data['consumer_key'], data['consumer_secret'])\n",
    "auth.set_access_token(data['access_token'], data['access_token_secret'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Produto escolhido:\n",
    "produto = 'Tesla'\n",
    "\n",
    "#Quantidade mínima de mensagens capturadas:\n",
    "n = 500\n",
    "#Quantidade mínima de mensagens para a base de treinamento:\n",
    "t = 450\n",
    "\n",
    "#Filtro de língua, escolha uma na tabela ISO 639-1.\n",
    "lang = 'en'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api = tweepy.API(auth)\n",
    "msgs = []\n",
    "msg_final=[]\n",
    "\n",
    "#Inicia a captura, para mais detalhes: ver a documentação do tweepy\n",
    "\n",
    "for msg in tweepy.Cursor(api.search, q=produto, lang=lang).items():  \n",
    "    msgs.append(msg.text.lower())\n",
    "    if len(msgs) > 50:\n",
    "        break\n",
    "msg_final = set(msgs)\n",
    "\n",
    "\n",
    "Final = []\n",
    "i = 0\n",
    "for e in msg_final:\n",
    "    Final.append(e)\n",
    "    if len (Final) >= 15:\n",
    "        break\n",
    "\n",
    "shuffle(Final)\n",
    "print (len(Final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultado_testeSF = aplica_algoritimoSF(Final)\n",
    "Tweet_testeS[\"Classificação do Algoritimo\"] = resultado_testeSF\n",
    "Tweet_testeSF.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aplica_algoritimoSF(Tweets):\n",
    "    \n",
    "    Tweets_lista = []\n",
    "    Tweet_valor = []\n",
    "\n",
    "    for e in Tweets:\n",
    "        Tweets_lista.append(stemmer.stem(cleanup(e.lower())))\n",
    "    \n",
    "    for e in Tweets_lista:\n",
    "        tweet_split = ajusta_emoji(e.split())\n",
    "        Tweet_valor.append(bayesS(tweet_split))\n",
    "    \n",
    "    return Tweet_valor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tweets_lista = []\n",
    "for e in Final:\n",
    "    Tweets_lista.append(stemmer.stem(cleanup(e.lower())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tweet_valor = []\n",
    "for e in Tweets_lista:\n",
    "        tweet_split = ajusta_emoji(e.split())\n",
    "        Tweet_valor.append(bayesS(tweet_split))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tweet_valor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Python program to demonstrate creating  \n",
    "# pandas Datadaframe from lists using zip.  \n",
    "    \n",
    "import pandas as pd  \n",
    "    \n",
    "# List1  \n",
    "Tweet = Final \n",
    "    \n",
    "# List2  \n",
    "valor = aplica_algoritimoSF(Final)\n",
    "    \n",
    "# get the list of tuples from two lists.  \n",
    "# and merge them by using zip().  \n",
    "list_of_tuples = list(zip(Tweet, valor))  \n",
    "    \n",
    "# Assign data to tuples.  \n",
    "list_of_tuples   \n",
    "  \n",
    "  \n",
    "# Converting lists of tuples into  \n",
    "# pandas Dataframe.  \n",
    "df = pd.DataFrame(list_of_tuples, columns = ['Tweet', 'Classificação'])  \n",
    "     \n",
    "# Print data.  \n",
    "df  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "#Instalando o tweepy\n",
    "!pip install tweepy\n",
    "\n",
    "import threading\n",
    "import tweepy\n",
    "import math\n",
    "import os.path\n",
    "import pandas as pd\n",
    "import json\n",
    "from random import shuffle\n",
    "\n",
    "def aplica_algoritimoSF(Tweets):\n",
    "    \n",
    "    Tweets_lista = []\n",
    "    Tweet_valor = []\n",
    "\n",
    "    for e in Tweets:\n",
    "        Tweets_lista.append(stemmer.stem(cleanup(e.lower())))\n",
    "    \n",
    "    for e in Tweets_lista:\n",
    "        tweet_split = ajusta_emoji(e.split())\n",
    "        Tweet_valor.append(bayesS(tweet_split))\n",
    "    \n",
    "    return Tweet_valor\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def printit():\n",
    "    threading.Timer(30.0, printit).start()\n",
    "    \n",
    "    with open('auth.pass') as fp:    \n",
    "        data = json.load(fp)\n",
    "        \n",
    "\n",
    "    auth = tweepy.OAuthHandler(data['consumer_key'], data['consumer_secret'])\n",
    "    auth.set_access_token(data['access_token'], data['access_token_secret'])\n",
    "\n",
    "\n",
    "    produto = 'Tesla'\n",
    "    n = 500\n",
    "    t = 450\n",
    "    lang = 'en'\n",
    "    \n",
    "    api = tweepy.API(auth)\n",
    "    msgs = []\n",
    "    msg_final=[]\n",
    "\n",
    "\n",
    "    for msg in tweepy.Cursor(api.search, q=produto, lang=lang).items():  \n",
    "        msgs.append(msg.text.lower())\n",
    "        if len(msgs) > 30:\n",
    "            break\n",
    "    msg_final = set(msgs)\n",
    "    \n",
    "    Final = []\n",
    "    i = 0\n",
    "    for e in msg_final:\n",
    "        Final.append(e)\n",
    "        if len (Final) >= 10:\n",
    "            break\n",
    "\n",
    "    shuffle(Final)\n",
    "    \n",
    "    \n",
    "\n",
    "     \n",
    "    Tweet = Final  \n",
    "    valor = aplica_algoritimoSF(Final)\n",
    "    \n",
    "    list_of_tuples = list(zip(Tweet, valor)) \n",
    "    list_of_tuples   \n",
    "    df = pd.DataFrame(list_of_tuples, columns = ['Tweet', 'Classificação'])\n",
    "    \n",
    "    return df,\"Rodou\" \n",
    "\n",
    "printit()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "\n",
    "def printit2():\n",
    "    threading.Timer(5.0, printit2).start()\n",
    "    print (\"Hello, World!\")\n",
    "    print (\"Hello, World!2\")\n",
    "printit2()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'heard'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer.stem(\"heard\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      rt @williamsbob75: another day, another lawsui...\n",
       "1      @tesla_truth wait!! they want me to give them ...\n",
       "2      @davinalexmma @motorcyclebum @tesla you can ge...\n",
       "3      rt @melaynalokosky: \"the best service, of cour...\n",
       "4      @evnewsdaily i'd happily give my money back to...\n",
       "5      rt @business: teslas have an autopilot functio...\n",
       "                             ...                        \n",
       "294    @nykchannel re. bug conversion: it will have f...\n",
       "295    on my way home today i saw a lady driving a te...\n",
       "296    rt @arikring: @txsharon @therealnumber6 @risep...\n",
       "297    @tesla_truth yes but #wework promotes veganism...\n",
       "298    @alterviggo @tesla @elonmusk i think what dies...\n",
       "299    tesla battery researcher unveils new cell that...\n",
       "Name: Teste, Length: 300, dtype: object"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Tweet_testeS['Teste']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
