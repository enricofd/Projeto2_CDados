{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "pd.options.display.max_rows = 13\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "\n",
    "def cleanup(text):\n",
    "    import string\n",
    "    punctuation = '[!-.:?;]'\n",
    "    pattern = re.compile(punctuation)\n",
    "    text_subbed = re.sub(pattern, ' ', text)\n",
    "    return text_subbed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tesla_raw = pd.read_excel (r'Tesla.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tesla_Negative = Tesla_raw[Tesla_raw[\"Classificação\"] == 0]\n",
    "Tesla_Positive = Tesla_raw[Tesla_raw[\"Classificação\"] == 1]\n",
    "Tesla_NR = Tesla_raw[Tesla_raw[\"Classificação\"] == 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tesla_Negative[\"Treinamento\"];\n",
    "Tesla_Positive[\"Treinamento\"];\n",
    "Tesla_NR[\"Treinamento\"];\n",
    "Tesla_raw[\"Treinamento\"];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tweets_N_Text = \"\"\n",
    "for e in Tesla_Negative[\"Treinamento\"]:\n",
    "    Tweets_N_Text += e\n",
    "\n",
    "Tweets_P_Text = \"\"\n",
    "for e in Tesla_Positive[\"Treinamento\"]:\n",
    "    Tweets_P_Text += e\n",
    "\n",
    "Tweets_NR_Text = \"\"\n",
    "for e in Tesla_NR[\"Treinamento\"]:\n",
    "    Tweets_NR_Text += e\n",
    "\n",
    "Tweets_R_Text = \"\"\n",
    "for e in Tesla_raw[\"Treinamento\"]:\n",
    "    Tweets_R_Text += e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tweets_N_TextClean = cleanup(Tweets_N_Text.lower())\n",
    "Tweets_P_TextClean = cleanup(Tweets_P_Text.lower())\n",
    "Tweets_NR_TextClean = cleanup(Tweets_NR_Text.lower())\n",
    "Tweets_R_TextClean = cleanup(Tweets_R_Text.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ajusta_emoji (lista): \n",
    "    \n",
    "    emoji_raw = \"🏳 🏴 🏁 🚩 🎌 🌈 ❤ 🧡 💛 💚 💙 💜 🖤 💔 ❣ 💕 💞 💓 💗 💖 💘 💝 💟 ☮ ✝ ☪ 🕉 ☸ ✡ 🔯 🕎 ☯ ☦ 🛐 ⛎ ♈ ♉ ♊ ♋ ♌ ♍ ♎ ♏ ♐ ♑ ♒ ♓ 🆔 ⚛ ⚕ ☢ ☣ 📴 📳 🈶 🈚 🈸 🈺 🈷 ✴ 🆚 🉑 💮 🉐 ㊙ ㊗ 🈴 🈵 🈹 🈲 🅰 🅱 🆎 🆑 🅾 🆘 ⛔ 📛 🚫 ❌ ⭕ 💢 ♨ 🚷 🚯 🚳 🚱 🔞 📵 🚭 ❗ ❕ ❓ ❔ ‼ ⁉ 💯 🔅 🔆 🔱 ⚜ 〽 ⚠ 🚸 🔰 ♻ 🈯 💹 ❇ ✳ ❎ ✅ 💠 🌀 ➿ 🌐 Ⓜ 🏧 🚾 ♿ 🅿 🈳 🈂 🛂 🛃 🛄 🛅 🚰 🚹 ♂ 🚺 ♀ 🚼 🚻 🚮 🎦 📶 🈁 🆖 🆗 🆙 🆒 🆕 🆓 0⃣ 1⃣ 2⃣ 3⃣ 4⃣ 5⃣ 6⃣ 7⃣ 8⃣ 9⃣ 🔟 🔢 ▶ ⏸ ⏯ ⏹ ⏺ ⏏ ⏭ ⏮ ⏩ ⏪ 🔀 🔁 🔂 ◀ 🔼 🔽 ⏫ ⏬ ➡ ⬅ ⬆ ⬇ ↗ ↘ ↙ ↖ ↕ ↔ 🔄 ↪ ↩ 🔃 ⤴ ⤵ #⃣ *⃣ ℹ 🔤 🔡 🔠 🔣 🎵 🎶 〰 ➰ ✔ ➕ ➖ ➗ ✖ 💲 💱 🔚 🔙 🔛 🔝 🔜 ☑ 🔘 ⚪ ⚫ 🔴 🔵 🔸 🔹 🔶 🔷 🔺 ▪ ▫ ⬛ ⬜ 🔻 ◼ ◻ ◾ ◽ 🔲 🔳 🔈 🔉 🔊 🔇 📣 📢 🔔 🔕 🃏 🀄 ♠ ♣ ♥ ♦ 🎴 👁‍🗨 🗨 💭 🗯 💬 🕐 🕑 🕒 🕓 🕔 🕕 🕖 🕗 🕘 🕙 🕚 🕛 🕜 🕝 🕞 🕟 🕠 🕡 🕢 🕣 🕤 🕥 🕦 🕧 😀 😬 😁 😂 😃 😄 🤣 😅 😆 😇 😉 😊 🙂 🙃 ☺ 😋 😌 😍 😘 😗 😙 😚 🤪 😜 😝 😛 🤑 😎 🤓 🧐 🤠 🤗 🤡 😏 😶 😐 😑 😒 🙄 🤨 🤔 🤫 🤭 🤥 😳 😞 😟 😠 😡 🤬 😔 😕 🙁 ☹ 😣 😖 😫 😩 😤 😮 😱 😨 😰 😯 😦 😧 😢 😥 😪 🤤 😓 😭 🤩 😵 😲 🤯 🤐 😷 🤕 🤒 🤮 🤢 🤧 😴 💤 😈 👿 👹 👺 💩 👻 💀 ☠ 👽 🤖 🎃 😺 😸 😹 😻 😼 😽 🙀 😿 😾 👐 🤲 🙌 👏 🙏 🤝 👍 👎 👊 ✊ 🤛 🤜 🤞 ✌ 🤘 🤟 👌 👈 👉 👆 👇 ☝ ✋ 🤚 🖐 🖖 👋 🤙 💪 🖕 ✍ 🤳 💅 👄 👅 👂 👃 👁 👀 🧠 👤 👥 🗣 👶 🧒 👦 👧 🧑 👨 🧔 👱‍♂️ 👩 👱‍♀️ 🧓 👴 👵 👲 👳‍♀️ 👳‍♂️ 🧕 👮‍♀️ 👮‍♂️ 👩‍🚒 👨‍🚒 👷‍♀️ 👷‍♂️ 👩‍🏭 👨‍🏭 👩‍🔧 👨‍🔧 👩‍🌾 👨‍🌾 👩‍🍳 👨‍🍳 👩‍🎤 👨‍🎤 👩‍🎨 👨‍🎨 👩‍🏫 👨‍🏫 👩‍🎓 👨‍🎓 👩‍💼 👨‍💼 👩‍💻 👨‍💻 👩‍🔬 👨‍🔬 👩‍🚀 👨‍🚀 👩‍⚕️ 👨‍⚕️ 👩‍⚖️ 👨‍⚖️ 👩‍✈️ 👨‍✈️ 💂‍♀️ 💂‍♂️ 🕵️‍♀️ 🕵️‍♂️ 🤶 🎅 👼 👸 🤴 👰 🤵‍♀️ 🤵 🕴️‍♀️ 🕴 🧙‍♀️ 🧙‍♂️ 🧝‍♀️ 🧝‍♂️ 🧚‍♀️ 🧚‍♂️ 🧞‍♀️ 🧞‍♂️ 🧜‍♀️ 🧜‍♂️ 🧛‍♀️ 🧛‍♂️ 🧟‍♀️ 🧟‍♂️ 🙇‍♀️ 🙇‍♂️ 💁‍♀️ 💁‍♂️ 🙅‍♀️ 🙅‍♂️ 🙆‍♀️ 🙆‍♂️ 🤷‍♀️ 🤷‍♂️ 🙋‍♀️ 🙋‍♂️ 🤦‍♀️ 🤦‍♂️ 🙎‍♀️ 🙎‍♂️ 🙍‍♀️ 🙍‍♂️ 💇‍♀️ 💇‍♂️ 💆‍♀️ 💆‍♂️ 🤰 🤱 🚶‍♀️ 🚶‍♂️ 🏃‍♀️ 🏃‍♂️ 💃 🕺 👯‍♀️ 👯‍♂️ 👫 👬 👭 💑 👩‍❤️‍👩 👨‍❤️‍👨 💏 👩‍❤️‍💋‍👩 👨‍❤️‍💋‍👨 👪 👨‍👩‍👧 👨‍👩‍👧‍👦 👨‍👩‍👦‍👦 👨‍👩‍👧‍👧 👩‍👩‍👦 👩‍👩‍👧 👩‍👩‍👧‍👦 👩‍👩‍👦‍👦 👩‍👩‍👧‍👧 👨‍👨‍👦 👨‍👨‍👧 👨‍👨‍👧‍👦 👨‍👨‍👦‍👦 👨‍👨‍👧‍👧 👩‍👦 👩‍👧 👩‍👧‍👦 👩‍👦‍👦 👩‍👧‍👧 👨‍👦 👨‍👧 👨‍👧‍👦 👨‍👦‍👦 👨‍👧‍👧 👚 👕 🧥 👖 👔 👗 👙 👘 💄 💋 👣 🧦 👠 👡 👢 👞 👟 🧢 👒 🎩 🎓 👑 ⛑ 🎒 👝 👛 👜 💼 👓 🕶 🧣 🧤 💍 🌂 ☂ ⌚ 📱 📲 💻 ⌨ 🖥 🖨 🖱 🖲 🕹 🗜 💽 💾 💿 📀 📼 📷 📸 📹 🎥 📽 🎞 📞 ☎ 📟 📠 📺 📻 🎙 🎚 🎛 ⏱ ⏲ ⏰ 🕰 ⏳ ⌛ 📡 🔋 🔌 💡 🔦 🕯 🗑 🛢 🛒 💸 💵 💴 💶 💷 💰 💳 💎 ⚖ 🔧 🔨 ⚒ 🛠 ⛏ 🔩 ⚙ ⛓ 🔫 💣 🔪 🗡 ⚔ 🛡 🚬 ⚰ ⚱ 🏺 🔮 📿 💈 ⚗ 🔭 🔬 🕳 💊 💉 🌡 🏷 🔖 🚽 🚿 🛁 🛀 🔑 🗝 🛋 🛌 🛏 🚪 🛎 🖼 🗺 ⛱ 🗿 🛍 🎈 🎏 🎀 🎁 🎊 🎉 🎎 🎐 🏮 ✉ 📩 📨 📧 💌 📮 📪 📫 📬 📭 📦 📯 📥 📤 📜 📃 📑 📊 📈 📉 📄 📅 📆 🗓 📇 🗃 🗳 🗄 📋 🗒 📁 📂 🗂 🗞 📰 📓 📕 📗 📘 📙 📔 📒 📚 📖 🔗 📎 🖇 ✂ 📐 📏 📌 📍 🔐 🔒 🔓 🔏 🖊 🖋 ✒ 📝 ✏ 🖍 🖌 🔍 🔎 🚗 🚕 🚙 🚌 🚎 🏎 🚓 🚑 🚒 🚐 🚚 🚛 🚜 🏍 🛵 🚲 🛴 🚨 🚔 🚍 🚘 🚖 🚡 🚠 🚟 🚃 🚋 🚝 🚄 🚅 🚈 🚞 🚂 🚆 🚇 🚊 🚉 🚁 🛩 ✈ 🛫 🛬 🛶 ⛵ 🛥 🚤 ⛴ 🛳 🚀 🛸 🛰 💺 ⚓ 🚧 ⛽ 🚏 🚦 🚥 🛑 🚢 🎡 🎢 🎠 🏗 🌁 🗼 🏭 ⛲ 🎑 ⛰ 🏔 🗻 🌋 🗾 🏕 ⛺ 🏞 🛣 🛤 🌅 🌄 🏜 🏖 🏝 🌇 🌆 🏙 🌃 🌉 🌌 🌠 🎇 🎆 🌈 🏘 🏰 🏯 🏟 🗽 🏠 🏡 🏚 🏢 🏬 🏣 🏤 🏥 🏦 🏨 🏪 🏫 🏩 💒 🏛 ⛪ 🕌 🕍 🕋 ⛩\"\n",
    "    emoji = emoji_raw.split()\n",
    "   \n",
    "    lista_emoji = []\n",
    "    palavra_limpa = []\n",
    "    \n",
    "    for e in lista:\n",
    "        palavra = ''\n",
    "        for letra in e:\n",
    "            if letra in emoji:\n",
    "                lista_emoji.append(letra)\n",
    "            else:\n",
    "                palavra += letra\n",
    "        palavra_limpa.append(palavra)\n",
    "    Final = lista_emoji + palavra_limpa\n",
    "    return Final\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "serie_N = pd.Series(ajusta_emoji(Tweets_N_TextClean.split()))\n",
    "serie_P = pd.Series(ajusta_emoji(Tweets_P_TextClean.split()))\n",
    "serie_NR = pd.Series(ajusta_emoji(Tweets_NR_TextClean.split()))\n",
    "serie_R = pd.Series(ajusta_emoji(Tweets_R_TextClean.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabela_N = serie_N.value_counts()\n",
    "tabela_P = serie_P.value_counts()\n",
    "tabela_NR = serie_NR.value_counts()\n",
    "tabela_R = serie_R.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_total = tabela_N.sum()\n",
    "P_total = tabela_P.sum()\n",
    "NR_total = tabela_NR.sum()\n",
    "R_total = len(tabela_R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Laplace_smoothing (x, cat):\n",
    "   \n",
    "    if cat == 0:\n",
    "        if x in tabela_N:\n",
    "            return (tabela_N[x] + 1) / (N_total + R_total)\n",
    "        else:\n",
    "            return (1) / (N_total + R_total)\n",
    "        \n",
    "    if cat == 1:\n",
    "        if x in tabela_P:\n",
    "            return (tabela_P[x] + 1) / (P_total + R_total)\n",
    "        else:\n",
    "            return (1) / (P_total + R_total)\n",
    "        \n",
    "    if cat == 2:\n",
    "        if x in tabela_NR:\n",
    "            return (tabela_NR[x] + 1) / (NR_total + R_total)\n",
    "        else:\n",
    "            return (1) / (NR_total + R_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bayes (Tweet):\n",
    "   \n",
    "    P0l = []\n",
    "    P1l = []\n",
    "    P2l = []\n",
    "    P0 = 1\n",
    "    P1 = 1\n",
    "    P2 = 1\n",
    "    \n",
    "    for e in Tweet:\n",
    "        P0l.append(Laplace_smoothing(e,0))\n",
    "        P1l.append(Laplace_smoothing(e,1))\n",
    "        P2l.append(Laplace_smoothing(e,2))\n",
    "    \n",
    "    for e in P0l:\n",
    "        P0 *= e\n",
    "    \n",
    "    for e in P1l:\n",
    "        P1 *= e\n",
    "        \n",
    "    for e in P2l:\n",
    "        P2 *= e\n",
    "    \n",
    "    if P0 > P1 and P0 > P2:\n",
    "        return (0)\n",
    "    \n",
    "    elif P1 > P0 and P1 > P2:\n",
    "        return (1)\n",
    "    \n",
    "    else:\n",
    "        return(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aplica_algoritimo(Tweets):\n",
    "\n",
    "    Tweets_lista = []\n",
    "    Tweet_valor = []\n",
    "\n",
    "    for e in Tweets['Teste']:\n",
    "        Tweets_lista.append(cleanup(e.lower()))\n",
    "    \n",
    "    for e in Tweets_lista:\n",
    "        tweet_split = ajusta_emoji(e.split())\n",
    "        Tweet_valor.append(bayes(tweet_split))\n",
    "    \n",
    "    return Tweet_valor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Teste</th>\n",
       "      <th>Classificação</th>\n",
       "      <th>Classificação do Algoritimo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rt @williamsbob75: another day, another lawsui...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@tesla_truth wait!! they want me to give them ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@davinalexmma @motorcyclebum @tesla you can ge...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rt @melaynalokosky: \"the best service, of cour...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@evnewsdaily i'd happily give my money back to...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>rt @business: teslas have an autopilot functio...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>$tsla - statement of changes in beneficial own...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>rt @insideevs: here's why tesla's h2 2019 will...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>rt @djdura: is there a bug or an extra feature...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>i need that lambo urus in off white and a tesl...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Teste  Classificação  \\\n",
       "0  rt @williamsbob75: another day, another lawsui...              2   \n",
       "1  @tesla_truth wait!! they want me to give them ...              1   \n",
       "2  @davinalexmma @motorcyclebum @tesla you can ge...              1   \n",
       "3  rt @melaynalokosky: \"the best service, of cour...              0   \n",
       "4  @evnewsdaily i'd happily give my money back to...              0   \n",
       "5  rt @business: teslas have an autopilot functio...              0   \n",
       "6  $tsla - statement of changes in beneficial own...              2   \n",
       "7  rt @insideevs: here's why tesla's h2 2019 will...              1   \n",
       "8  rt @djdura: is there a bug or an extra feature...              0   \n",
       "9  i need that lambo urus in off white and a tesl...              1   \n",
       "\n",
       "   Classificação do Algoritimo  \n",
       "0                            0  \n",
       "1                            1  \n",
       "2                            2  \n",
       "3                            0  \n",
       "4                            2  \n",
       "5                            0  \n",
       "6                            1  \n",
       "7                            1  \n",
       "8                            1  \n",
       "9                            1  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Tweet_teste = pd.read_excel (r'Tesla.xlsx', sheet_name = 'Teste', index = False)\n",
    "resultado_teste = aplica_algoritimo(Tweet_teste)\n",
    "Tweet_teste[\"Classificação do Algoritimo\"] = resultado_teste\n",
    "Tweet_teste.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com stemming:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "NCP = (Tweets_N_TextClean.split())\n",
    "PCP = (Tweets_P_TextClean.split())\n",
    "NRCP = (Tweets_NR_TextClean.split())\n",
    "RCP = (Tweets_R_TextClean.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_N = []\n",
    "for e in NCP:\n",
    "    j = stemmer.stem(e)\n",
    "    lista_N.append(j)\n",
    "    \n",
    "\n",
    "lista_P = []\n",
    "for e in PCP:\n",
    "    j = stemmer.stem(e)\n",
    "    lista_P.append(j)\n",
    "\n",
    "\n",
    "lista_NR = []\n",
    "for e in NRCP:\n",
    "    j = stemmer.stem(e)\n",
    "    lista_NR.append(j)\n",
    "\n",
    "lista_R = []\n",
    "for e in RCP:\n",
    "    j = stemmer.stem(e)\n",
    "    lista_R.append(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "serie_NS = pd.Series(ajusta_emoji(lista_N))\n",
    "serie_PS = pd.Series(ajusta_emoji(lista_P))\n",
    "serie_NRS = pd.Series(ajusta_emoji(lista_NR))\n",
    "serie_RS = pd.Series(ajusta_emoji(lista_R))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabela_NS = serie_NS.value_counts()\n",
    "tabela_PS = serie_PS.value_counts()\n",
    "tabela_NRS = serie_NRS.value_counts()\n",
    "tabela_RS = serie_RS.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_totalS = tabela_NS.sum()\n",
    "P_totalS = tabela_PS.sum()\n",
    "NR_totalS = tabela_NRS.sum()\n",
    "R_totalS = len(tabela_RS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Laplace_smoothingS (x, cat):\n",
    "   \n",
    "    if cat == 0:\n",
    "        if x in tabela_NS:\n",
    "            return (tabela_NS[x] + 1) / (N_totalS + R_totalS)\n",
    "        else:\n",
    "            return (1) / (N_totalS + R_totalS)\n",
    "        \n",
    "    if cat == 1:\n",
    "        if x in tabela_PS:\n",
    "            return (tabela_PS[x] + 1) / (P_totalS + R_totalS)\n",
    "        else:\n",
    "            return (1) / (P_totalS + R_totalS)\n",
    "        \n",
    "    if cat == 2:\n",
    "        if x in tabela_NRS:\n",
    "            return (tabela_NRS[x] + 1) / (NR_totalS + R_totalS)\n",
    "        else:\n",
    "            return (1) / (NR_totalS + R_totalS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bayesS (Tweet):\n",
    "   \n",
    "    P0l = []\n",
    "    P1l = []\n",
    "    P2l = []\n",
    "    P0 = 1\n",
    "    P1 = 1\n",
    "    P2 = 1\n",
    "    \n",
    "    for e in Tweet:\n",
    "        P0l.append(Laplace_smoothingS(e,0))\n",
    "        P1l.append(Laplace_smoothingS(e,1))\n",
    "        P2l.append(Laplace_smoothingS(e,2))\n",
    "    \n",
    "    for e in P0l:\n",
    "        P0 *= e\n",
    "    \n",
    "    for e in P1l:\n",
    "        P1 *= e\n",
    "        \n",
    "    for e in P2l:\n",
    "        P2 *= e\n",
    "    \n",
    "    if P0 > P1 and P0 > P2:\n",
    "        return (0)\n",
    "    \n",
    "    elif P1 > P0 and P1 > P2:\n",
    "        return (1)\n",
    "    \n",
    "    else:\n",
    "        return(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aplica_algoritimoS(Tweets):\n",
    "    \n",
    "    Tweets_lista = []\n",
    "    Tweet_valor = []\n",
    "\n",
    "    for e in Tweets['Teste']:\n",
    "        Tweets_lista.append(stemmer.stem(cleanup(e.lower())))\n",
    "    \n",
    "    for e in Tweets_lista:\n",
    "        tweet_split = ajusta_emoji(e.split())\n",
    "        Tweet_valor.append(bayesS(tweet_split))\n",
    "    \n",
    "    return Tweet_valor\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Teste</th>\n",
       "      <th>Classificação</th>\n",
       "      <th>Classificação do Algoritimo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rt @williamsbob75: another day, another lawsui...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@tesla_truth wait!! they want me to give them ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@davinalexmma @motorcyclebum @tesla you can ge...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rt @melaynalokosky: \"the best service, of cour...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@evnewsdaily i'd happily give my money back to...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>rt @business: teslas have an autopilot functio...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>$tsla - statement of changes in beneficial own...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>rt @insideevs: here's why tesla's h2 2019 will...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>rt @djdura: is there a bug or an extra feature...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>i need that lambo urus in off white and a tesl...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Teste  Classificação  \\\n",
       "0  rt @williamsbob75: another day, another lawsui...              2   \n",
       "1  @tesla_truth wait!! they want me to give them ...              1   \n",
       "2  @davinalexmma @motorcyclebum @tesla you can ge...              1   \n",
       "3  rt @melaynalokosky: \"the best service, of cour...              0   \n",
       "4  @evnewsdaily i'd happily give my money back to...              0   \n",
       "5  rt @business: teslas have an autopilot functio...              0   \n",
       "6  $tsla - statement of changes in beneficial own...              2   \n",
       "7  rt @insideevs: here's why tesla's h2 2019 will...              1   \n",
       "8  rt @djdura: is there a bug or an extra feature...              0   \n",
       "9  i need that lambo urus in off white and a tesl...              1   \n",
       "\n",
       "   Classificação do Algoritimo  \n",
       "0                            1  \n",
       "1                            1  \n",
       "2                            1  \n",
       "3                            1  \n",
       "4                            0  \n",
       "5                            0  \n",
       "6                            1  \n",
       "7                            1  \n",
       "8                            0  \n",
       "9                            1  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Tweet_testeS = pd.read_excel (r'Tesla.xlsx', sheet_name = 'Teste', index = False)\n",
    "resultado_testeS = aplica_algoritimoS(Tweet_testeS)\n",
    "Tweet_testeS[\"Classificação do Algoritimo\"] = resultado_testeS\n",
    "Tweet_testeS.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparando:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_normAL = []\n",
    "for e in Tweet_teste['Classificação do Algoritimo']:\n",
    "             class_normAL.append(e)\n",
    "\n",
    "class_norm = []\n",
    "for e in Tweet_teste['Classificação']:\n",
    "             class_norm.append(e)\n",
    "            \n",
    "        \n",
    "    \n",
    "class_SAL = []\n",
    "for e in Tweet_testeS['Classificação do Algoritimo']:\n",
    "             class_SAL.append(e)\n",
    "\n",
    "class_S = []\n",
    "for e in Tweet_testeS['Classificação']:\n",
    "             class_S.append(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "e = 0\n",
    "while i < len(class_norm):\n",
    "    if class_normAL[i] == class_norm[i]:\n",
    "        e += 1\n",
    "    i += 1\n",
    "print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "167\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "e = 0\n",
    "while i < len(class_norm):\n",
    "    if class_SAL[i] == class_S[i]:\n",
    "        e += 1\n",
    "    i += 1\n",
    "print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "1 0 0\n",
      "8\n",
      "0 1 0\n",
      "14\n",
      "1 0 0\n",
      "16\n",
      "1 0 0\n",
      "18\n",
      "1 0 0\n",
      "28\n",
      "1 0 1\n",
      "32\n",
      "1 0 0\n",
      "33\n",
      "1 0 0\n",
      "36\n",
      "1 0 1\n",
      "39\n",
      "0 1 1\n",
      "54\n",
      "2 1 1\n",
      "58\n",
      "1 0 1\n",
      "59\n",
      "0 1 1\n",
      "63\n",
      "1 0 0\n",
      "65\n",
      "1 0 0\n",
      "66\n",
      "1 0 1\n",
      "75\n",
      "1 0 1\n",
      "78\n",
      "1 0 1\n",
      "91\n",
      "1 0 1\n",
      "104\n",
      "2 1 1\n",
      "110\n",
      "0 1 1\n",
      "111\n",
      "0 1 0\n",
      "113\n",
      "0 1 1\n",
      "114\n",
      "1 0 0\n",
      "130\n",
      "1 0 0\n",
      "136\n",
      "1 0 0\n",
      "139\n",
      "1 0 0\n",
      "140\n",
      "1 0 0\n",
      "141\n",
      "0 1 1\n",
      "145\n",
      "1 0 1\n",
      "150\n",
      "1 0 0\n",
      "159\n",
      "1 0 0\n",
      "174\n",
      "1 0 0\n",
      "177\n",
      "0 1 1\n",
      "179\n",
      "2 0 0\n",
      "181\n",
      "1 0 1\n",
      "187\n",
      "1 0 0\n",
      "188\n",
      "0 1 1\n",
      "206\n",
      "2 1 1\n",
      "218\n",
      "2 0 1\n",
      "228\n",
      "1 0 1\n",
      "241\n",
      "1 0 1\n",
      "244\n",
      "1 0 1\n",
      "249\n",
      "2 1 0\n",
      "252\n",
      "1 0 0\n",
      "259\n",
      "1 0 0\n",
      "269\n",
      "0 1 0\n",
      "272\n",
      "1 0 0\n",
      "282\n",
      "1 0 0\n",
      "294\n",
      "2 1 1\n",
      "298\n",
      "1 0 1\n",
      "51\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "e = 0\n",
    "while i < len(class_S):\n",
    "    if class_SAL[i] != class_normAL[i]:\n",
    "        e += 1\n",
    "        print(i)\n",
    "        print(class_SAL[i],class_normAL[i],class_norm[i] )\n",
    "    i += 1\n",
    "print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Melhora banco de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seleciona_errados (tabela):\n",
    "    i = 0\n",
    "    erros1 = []\n",
    "    erros2 = []\n",
    "    while i < len (tabela['Classificação']):\n",
    "        if tabela['Classificação'][i] != tabela['Classificação do Algoritimo'][i]:\n",
    "            erros1.append(tabela[\"Teste\"][i]) \n",
    "            erros2.append(tabela[\"Classificação\"][i])\n",
    "        i += 1\n",
    "    return erros1, erros2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"Teste.csv\", \"a\") as myfile:\n",
    "    for e in seleciona_errados (Tweet_testeS)[0]:\n",
    "        x = (e.encode(\"utf-8\"))\n",
    "        myfile.write(f\"{x}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os.path\n",
    "import pandas as pd\n",
    "import json\n",
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Treinamento</th>\n",
       "      <th>Classificação</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@davinalexmma @motorcyclebum @tesla you can ge...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@evnewsdaily i'd happily give my money back to...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>$tsla - statement of changes in beneficial own...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rt @bridieev: .@tesla #model3 sales in #austra...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://t.co/kux1s3jitt\\n\\nelectric ford f-150...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>rt @itshovah: this is the tesla winner.. nice....</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>@aggersv @jason @tesla yup. so you wouldn’t ha...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>@sensarpensar @tesla_truth they actually did t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>wow, i think i need to follow gerard detourbet...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>@mindstatex nobody sleeps like that and wakes ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>‘based on the results of ford’s study, there i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>@alterviggo @tesla @elonmusk i think what dies...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>125 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Treinamento  Classificação\n",
       "0    @davinalexmma @motorcyclebum @tesla you can ge...              1\n",
       "1    @evnewsdaily i'd happily give my money back to...              0\n",
       "2    $tsla - statement of changes in beneficial own...              2\n",
       "3    rt @bridieev: .@tesla #model3 sales in #austra...              1\n",
       "4    https://t.co/kux1s3jitt\\n\\nelectric ford f-150...              0\n",
       "5    rt @itshovah: this is the tesla winner.. nice....              1\n",
       "..                                                 ...            ...\n",
       "119  @aggersv @jason @tesla yup. so you wouldn’t ha...              0\n",
       "120  @sensarpensar @tesla_truth they actually did t...              1\n",
       "121  wow, i think i need to follow gerard detourbet...              2\n",
       "122  @mindstatex nobody sleeps like that and wakes ...              2\n",
       "123  ‘based on the results of ford’s study, there i...              1\n",
       "124  @alterviggo @tesla @elonmusk i think what dies...              1\n",
       "\n",
       "[125 rows x 2 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# intialise data of lists. \n",
    "data = {'Treinamento':seleciona_errados(Tweet_testeS)[0], 'Classificação':seleciona_errados(Tweet_testeS)[1]} \n",
    "  \n",
    "# Create DataFrame \n",
    "df = pd.DataFrame(data) \n",
    "  \n",
    "# Print the output. \n",
    "df \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "125"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(seleciona_errados(Tweet_testeS)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Verifica se o arquivo não existe para não substituir um conjunto pronto\n",
    "if not os.path.isfile('Teste.xlsx'):\n",
    "    \n",
    "    #Abre o arquivo para escrita\n",
    "    writer = pd.ExcelWriter('Teste.xlsx')\n",
    "\n",
    "    #divide o conjunto de mensagens em duas planilhas\n",
    "    dft = df\n",
    "    dft.to_excel(excel_writer = writer, sheet_name = 'Treinamento', index = False)\n",
    "    \n",
    "    #fecha o arquivo\n",
    "    writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'seleciona_errados' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-6b5c67fecbb6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# intialise data of lists.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'Treinamento'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mseleciona_errados\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTweet_testeS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mTesla_raw\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Treinamento\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Classificação'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mseleciona_errados\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTweet_testeS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mTesla_raw\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Classificação\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Create DataFrame\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'seleciona_errados' is not defined"
     ]
    }
   ],
   "source": [
    "# intialise data of lists. \n",
    "data = {'Treinamento':seleciona_errados(Tweet_testeS)[0] + Tesla_raw[\"Treinamento\"], 'Classificação':seleciona_errados(Tweet_testeS)[1] + Tesla_raw[\"Classificação\"]} \n",
    "  \n",
    "# Create DataFrame \n",
    "df = pd.DataFrame(data) \n",
    "  \n",
    "# Print the output. \n",
    "df \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                          @tesla when coming to turkey?\n",
       "1      @teslamodel3fan @vincent13031925 where i live ...\n",
       "2      the tesla has auto pilot so it’s fine. maybe t...\n",
       "3      @jason @weworkadam did elon not also buy a jet...\n",
       "4      rt @samjmintz: interesting note from ntsb's te...\n",
       "5      @italianmaster @business @ford @teamchevy @dod...\n",
       "                             ...                        \n",
       "444    @robotbeat @tesla_truth @sustainerr @anshid_np...\n",
       "445    @captgibb @tesla_truth dan neil has an interes...\n",
       "446    design news webinar focuses on the tesla batte...\n",
       "447    elon musk: tesla pickup truck pushed back to n...\n",
       "448    rt @issamahmed: mighty impressive from what i'...\n",
       "449    rt @vievararosel: @podcast_spain there were no...\n",
       "Name: Treinamento, Length: 450, dtype: object"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if not os.path.isfile('Teste.xlsx'):\n",
    "    \n",
    "    #Abre o arquivo para escrita\n",
    "    writer = pd.ExcelWriter('Teste.xlsx')\n",
    "\n",
    "    #divide o conjunto de mensagens em duas planilhas\n",
    "    dft = df\n",
    "    dft.to_excel(excel_writer = writer, sheet_name = 'Treinamento', index = False)\n",
    "    \n",
    "    #fecha o arquivo\n",
    "    writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      1\n",
       "1      1\n",
       "2      1\n",
       "3      0\n",
       "4      1\n",
       "5      1\n",
       "      ..\n",
       "444    2\n",
       "445    1\n",
       "446    1\n",
       "447    0\n",
       "448    0\n",
       "449    2\n",
       "Name: Classificação, Length: 450, dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Tesla_raw[\"Classificação\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tempo real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "#Instalando o tweepy\n",
    "!pip install tweepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import math\n",
    "import os.path\n",
    "import pandas as pd\n",
    "import json\n",
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dados de autenticação do twitter:\n",
    "\n",
    "#Coloque aqui o identificador da conta no twitter: @fulano\n",
    "\n",
    "#leitura do arquivo no formato JSON\n",
    "with open('auth.pass') as fp:    \n",
    "    data = json.load(fp)\n",
    "\n",
    "#Configurando a biblioteca. Não modificar\n",
    "auth = tweepy.OAuthHandler(data['consumer_key'], data['consumer_secret'])\n",
    "auth.set_access_token(data['access_token'], data['access_token_secret'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Produto escolhido:\n",
    "produto = 'Tesla'\n",
    "\n",
    "#Quantidade mínima de mensagens capturadas:\n",
    "n = 500\n",
    "#Quantidade mínima de mensagens para a base de treinamento:\n",
    "t = 450\n",
    "\n",
    "#Filtro de língua, escolha uma na tabela ISO 639-1.\n",
    "lang = 'en'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api = tweepy.API(auth)\n",
    "msgs = []\n",
    "msg_final=[]\n",
    "\n",
    "#Inicia a captura, para mais detalhes: ver a documentação do tweepy\n",
    "\n",
    "for msg in tweepy.Cursor(api.search, q=produto, lang=lang).items():  \n",
    "    msgs.append(msg.text.lower())\n",
    "    if len(msgs) > 50:\n",
    "        break\n",
    "msg_final = set(msgs)\n",
    "\n",
    "\n",
    "Final = []\n",
    "i = 0\n",
    "for e in msg_final:\n",
    "    Final.append(e)\n",
    "    if len (Final) >= 15:\n",
    "        break\n",
    "\n",
    "shuffle(Final)\n",
    "print (len(Final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultado_testeSF = aplica_algoritimoSF(Final)\n",
    "Tweet_testeS[\"Classificação do Algoritimo\"] = resultado_testeSF\n",
    "Tweet_testeSF.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aplica_algoritimoSF(Tweets):\n",
    "    \n",
    "    Tweets_lista = []\n",
    "    Tweet_valor = []\n",
    "\n",
    "    for e in Tweets:\n",
    "        Tweets_lista.append(stemmer.stem(cleanup(e.lower())))\n",
    "    \n",
    "    for e in Tweets_lista:\n",
    "        tweet_split = ajusta_emoji(e.split())\n",
    "        Tweet_valor.append(bayesS(tweet_split))\n",
    "    \n",
    "    return Tweet_valor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tweets_lista = []\n",
    "for e in Final:\n",
    "    Tweets_lista.append(stemmer.stem(cleanup(e.lower())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tweet_valor = []\n",
    "for e in Tweets_lista:\n",
    "        tweet_split = ajusta_emoji(e.split())\n",
    "        Tweet_valor.append(bayesS(tweet_split))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tweet_valor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Python program to demonstrate creating  \n",
    "# pandas Datadaframe from lists using zip.  \n",
    "    \n",
    "import pandas as pd  \n",
    "    \n",
    "# List1  \n",
    "Tweet = Final \n",
    "    \n",
    "# List2  \n",
    "valor = aplica_algoritimoSF(Final)\n",
    "    \n",
    "# get the list of tuples from two lists.  \n",
    "# and merge them by using zip().  \n",
    "list_of_tuples = list(zip(Tweet, valor))  \n",
    "    \n",
    "# Assign data to tuples.  \n",
    "list_of_tuples   \n",
    "  \n",
    "  \n",
    "# Converting lists of tuples into  \n",
    "# pandas Dataframe.  \n",
    "df = pd.DataFrame(list_of_tuples, columns = ['Tweet', 'Classificação'])  \n",
    "     \n",
    "# Print data.  \n",
    "df  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "#Instalando o tweepy\n",
    "!pip install tweepy\n",
    "\n",
    "import threading\n",
    "import tweepy\n",
    "import math\n",
    "import os.path\n",
    "import pandas as pd\n",
    "import json\n",
    "from random import shuffle\n",
    "\n",
    "def aplica_algoritimoSF(Tweets):\n",
    "    \n",
    "    Tweets_lista = []\n",
    "    Tweet_valor = []\n",
    "\n",
    "    for e in Tweets:\n",
    "        Tweets_lista.append(stemmer.stem(cleanup(e.lower())))\n",
    "    \n",
    "    for e in Tweets_lista:\n",
    "        tweet_split = ajusta_emoji(e.split())\n",
    "        Tweet_valor.append(bayesS(tweet_split))\n",
    "    \n",
    "    return Tweet_valor\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(                                               Tweet  Classificação\n",
       " 0  rt @mahobili: how the fuck are pakistanis affo...              0\n",
       " 1  @davidcorndc @gtconway3d @realdonaldtrump f**k...              0\n",
       " 2  rt @zonephysics: reaction of gasses to mini te...              2\n",
       " 3  @cgtnofficial beautiful cars.  try to oem tesl...              2\n",
       " 4  rt @tool_grinder: on behalf of manufacturers e...              2\n",
       " 5  rt @alex_avoigt: to all people interested in a...              2\n",
       " 6  @elonbachman @karpathy @elonmusk @tesla it’s p...              2\n",
       " 7  rt @samuelcchristo: 3 weeks in twitter purgato...              2\n",
       " 8      @audi try all you want, but it's not a tesla.              1\n",
       " 9  rt @roshenmaghhan: so a few months back, i was...              2, 'Rodou')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-62:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Enrico Damiani\\Anaconda3\\lib\\threading.py\", line 917, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\Enrico Damiani\\Anaconda3\\lib\\threading.py\", line 1166, in run\n",
      "    self.function(*self.args, **self.kwargs)\n",
      "  File \"<ipython-input-39-ea3ae97144d1>\", line 22, in printit\n",
      "    for msg in tweepy.Cursor(api.search, q=produto, lang=lang).items():\n",
      "  File \"C:\\Users\\Enrico Damiani\\Anaconda3\\lib\\site-packages\\tweepy\\cursor.py\", line 47, in __next__\n",
      "    return self.next()\n",
      "  File \"C:\\Users\\Enrico Damiani\\Anaconda3\\lib\\site-packages\\tweepy\\cursor.py\", line 195, in next\n",
      "    self.current_page = self.page_iterator.next()\n",
      "  File \"C:\\Users\\Enrico Damiani\\Anaconda3\\lib\\site-packages\\tweepy\\cursor.py\", line 106, in next\n",
      "    data = self.method(max_id=self.max_id, parser=RawParser(), *self.args, **self.kargs)\n",
      "  File \"C:\\Users\\Enrico Damiani\\Anaconda3\\lib\\site-packages\\tweepy\\binder.py\", line 250, in _call\n",
      "    return method.execute()\n",
      "  File \"C:\\Users\\Enrico Damiani\\Anaconda3\\lib\\site-packages\\tweepy\\binder.py\", line 233, in execute\n",
      "    raise TweepError(error_msg, resp, api_code=api_error_code)\n",
      "tweepy.error.TweepError: Twitter error response: status code = 429\n",
      "\n",
      "Exception in thread Thread-61:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Enrico Damiani\\Anaconda3\\lib\\threading.py\", line 917, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\Enrico Damiani\\Anaconda3\\lib\\threading.py\", line 1166, in run\n",
      "    self.function(*self.args, **self.kwargs)\n",
      "  File \"<ipython-input-39-ea3ae97144d1>\", line 22, in printit\n",
      "    for msg in tweepy.Cursor(api.search, q=produto, lang=lang).items():\n",
      "  File \"C:\\Users\\Enrico Damiani\\Anaconda3\\lib\\site-packages\\tweepy\\cursor.py\", line 47, in __next__\n",
      "    return self.next()\n",
      "  File \"C:\\Users\\Enrico Damiani\\Anaconda3\\lib\\site-packages\\tweepy\\cursor.py\", line 195, in next\n",
      "    self.current_page = self.page_iterator.next()\n",
      "  File \"C:\\Users\\Enrico Damiani\\Anaconda3\\lib\\site-packages\\tweepy\\cursor.py\", line 106, in next\n",
      "    data = self.method(max_id=self.max_id, parser=RawParser(), *self.args, **self.kargs)\n",
      "  File \"C:\\Users\\Enrico Damiani\\Anaconda3\\lib\\site-packages\\tweepy\\binder.py\", line 250, in _call\n",
      "    return method.execute()\n",
      "  File \"C:\\Users\\Enrico Damiani\\Anaconda3\\lib\\site-packages\\tweepy\\binder.py\", line 233, in execute\n",
      "    raise TweepError(error_msg, resp, api_code=api_error_code)\n",
      "tweepy.error.TweepError: Twitter error response: status code = 429\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def printit():\n",
    "    threading.Timer(30.0, printit).start()\n",
    "    \n",
    "    with open('auth.pass') as fp:    \n",
    "        data = json.load(fp)\n",
    "        \n",
    "\n",
    "    auth = tweepy.OAuthHandler(data['consumer_key'], data['consumer_secret'])\n",
    "    auth.set_access_token(data['access_token'], data['access_token_secret'])\n",
    "\n",
    "\n",
    "    produto = 'Tesla'\n",
    "    n = 500\n",
    "    t = 450\n",
    "    lang = 'en'\n",
    "    \n",
    "    api = tweepy.API(auth)\n",
    "    msgs = []\n",
    "    msg_final=[]\n",
    "\n",
    "\n",
    "    for msg in tweepy.Cursor(api.search, q=produto, lang=lang).items():  \n",
    "        msgs.append(msg.text.lower())\n",
    "        if len(msgs) > 30:\n",
    "            break\n",
    "    msg_final = set(msgs)\n",
    "    \n",
    "    Final = []\n",
    "    i = 0\n",
    "    for e in msg_final:\n",
    "        Final.append(e)\n",
    "        if len (Final) >= 10:\n",
    "            break\n",
    "\n",
    "    shuffle(Final)\n",
    "    \n",
    "    \n",
    "\n",
    "     \n",
    "    Tweet = Final  \n",
    "    valor = aplica_algoritimoSF(Final)\n",
    "    \n",
    "    list_of_tuples = list(zip(Tweet, valor)) \n",
    "    list_of_tuples   \n",
    "    df = pd.DataFrame(list_of_tuples, columns = ['Tweet', 'Classificação'])\n",
    "    \n",
    "    return df,\"Rodou\" \n",
    "\n",
    "printit()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "\n",
    "def printit2():\n",
    "    threading.Timer(5.0, printit2).start()\n",
    "    print (\"Hello, World!\")\n",
    "    print (\"Hello, World!2\")\n",
    "printit2()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
