{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 2 - Ciência dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nome: Enrico Francesco Damiani\n",
    "\n",
    "Nome: Felipe Junqueira"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classificador automático de sentimento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objetivo:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esse trabalho possui como objetivo o desenvolvimento de um classificador automático de sentimento voltado para tweets da Tesla. Para tanto, fez-se o download de 450 tweets voltados a essa empresa que foram classificados manualmente como sendo negativo (0), positivo (1) ou não relevante (2). Em posse do banco de dados, desenvolveu-se o codigo que seria responsável por classificar novos tweets, justamente por meio do banco de dados. Para medir os acertos do código, foram baixados mais 300 tweets que foram classificados manualmente e posteriormente fornecidos ao código para que também os classificasse. Comparando ambos, pode-se aferir a eficácia desse classificador. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Importando as bibliotecas a serem utlizadas:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "from IPython.display import display\n",
    "from nltk.stem import PorterStemmer\n",
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Funções utilizadas:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Função responsável por limpar os Tweets:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanup(text):\n",
    "    punctuation = '[!-.:?;]'\n",
    "    pattern = re.compile(punctuation)\n",
    "    text_subbed = re.sub(pattern, ' ', text)\n",
    "    return text_subbed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Função responsável por separar os emojis das palavras:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ajusta_emoji (lista): \n",
    "    \n",
    "    emoji_raw = \"🏳 🏴 🏁 🚩 🎌 🌈 ❤ 🧡 💛 💚 💙 💜 🖤 💔 ❣ 💕 💞 💓 💗 💖 💘 💝 💟 ☮ ✝ ☪ 🕉 ☸ ✡ 🔯 🕎 ☯ ☦ 🛐 ⛎ ♈ ♉ ♊ ♋ ♌ ♍ ♎ ♏ ♐ ♑ ♒ ♓ 🆔 ⚛ ⚕ ☢ ☣ 📴 📳 🈶 🈚 🈸 🈺 🈷 ✴ 🆚 🉑 💮 🉐 ㊙ ㊗ 🈴 🈵 🈹 🈲 🅰 🅱 🆎 🆑 🅾 🆘 ⛔ 📛 🚫 ❌ ⭕ 💢 ♨ 🚷 🚯 🚳 🚱 🔞 📵 🚭 ❗ ❕ ❓ ❔ ‼ ⁉ 💯 🔅 🔆 🔱 ⚜ 〽 ⚠ 🚸 🔰 ♻ 🈯 💹 ❇ ✳ ❎ ✅ 💠 🌀 ➿ 🌐 Ⓜ 🏧 🚾 ♿ 🅿 🈳 🈂 🛂 🛃 🛄 🛅 🚰 🚹 ♂ 🚺 ♀ 🚼 🚻 🚮 🎦 📶 🈁 🆖 🆗 🆙 🆒 🆕 🆓 0⃣ 1⃣ 2⃣ 3⃣ 4⃣ 5⃣ 6⃣ 7⃣ 8⃣ 9⃣ 🔟 🔢 ▶ ⏸ ⏯ ⏹ ⏺ ⏏ ⏭ ⏮ ⏩ ⏪ 🔀 🔁 🔂 ◀ 🔼 🔽 ⏫ ⏬ ➡ ⬅ ⬆ ⬇ ↗ ↘ ↙ ↖ ↕ ↔ 🔄 ↪ ↩ 🔃 ⤴ ⤵ #⃣ *⃣ ℹ 🔤 🔡 🔠 🔣 🎵 🎶 〰 ➰ ✔ ➕ ➖ ➗ ✖ 💲 💱 🔚 🔙 🔛 🔝 🔜 ☑ 🔘 ⚪ ⚫ 🔴 🔵 🔸 🔹 🔶 🔷 🔺 ▪ ▫ ⬛ ⬜ 🔻 ◼ ◻ ◾ ◽ 🔲 🔳 🔈 🔉 🔊 🔇 📣 📢 🔔 🔕 🃏 🀄 ♠ ♣ ♥ ♦ 🎴 👁‍🗨 🗨 💭 🗯 💬 🕐 🕑 🕒 🕓 🕔 🕕 🕖 🕗 🕘 🕙 🕚 🕛 🕜 🕝 🕞 🕟 🕠 🕡 🕢 🕣 🕤 🕥 🕦 🕧 😀 😬 😁 😂 😃 😄 🤣 😅 😆 😇 😉 😊 🙂 🙃 ☺ 😋 😌 😍 😘 😗 😙 😚 🤪 😜 😝 😛 🤑 😎 🤓 🧐 🤠 🤗 🤡 😏 😶 😐 😑 😒 🙄 🤨 🤔 🤫 🤭 🤥 😳 😞 😟 😠 😡 🤬 😔 😕 🙁 ☹ 😣 😖 😫 😩 😤 😮 😱 😨 😰 😯 😦 😧 😢 😥 😪 🤤 😓 😭 🤩 😵 😲 🤯 🤐 😷 🤕 🤒 🤮 🤢 🤧 😴 💤 😈 👿 👹 👺 💩 👻 💀 ☠ 👽 🤖 🎃 😺 😸 😹 😻 😼 😽 🙀 😿 😾 👐 🤲 🙌 👏 🙏 🤝 👍 👎 👊 ✊ 🤛 🤜 🤞 ✌ 🤘 🤟 👌 👈 👉 👆 👇 ☝ ✋ 🤚 🖐 🖖 👋 🤙 💪 🖕 ✍ 🤳 💅 👄 👅 👂 👃 👁 👀 🧠 👤 👥 🗣 👶 🧒 👦 👧 🧑 👨 🧔 👱‍♂️ 👩 👱‍♀️ 🧓 👴 👵 👲 👳‍♀️ 👳‍♂️ 🧕 👮‍♀️ 👮‍♂️ 👩‍🚒 👨‍🚒 👷‍♀️ 👷‍♂️ 👩‍🏭 👨‍🏭 👩‍🔧 👨‍🔧 👩‍🌾 👨‍🌾 👩‍🍳 👨‍🍳 👩‍🎤 👨‍🎤 👩‍🎨 👨‍🎨 👩‍🏫 👨‍🏫 👩‍🎓 👨‍🎓 👩‍💼 👨‍💼 👩‍💻 👨‍💻 👩‍🔬 👨‍🔬 👩‍🚀 👨‍🚀 👩‍⚕️ 👨‍⚕️ 👩‍⚖️ 👨‍⚖️ 👩‍✈️ 👨‍✈️ 💂‍♀️ 💂‍♂️ 🕵️‍♀️ 🕵️‍♂️ 🤶 🎅 👼 👸 🤴 👰 🤵‍♀️ 🤵 🕴️‍♀️ 🕴 🧙‍♀️ 🧙‍♂️ 🧝‍♀️ 🧝‍♂️ 🧚‍♀️ 🧚‍♂️ 🧞‍♀️ 🧞‍♂️ 🧜‍♀️ 🧜‍♂️ 🧛‍♀️ 🧛‍♂️ 🧟‍♀️ 🧟‍♂️ 🙇‍♀️ 🙇‍♂️ 💁‍♀️ 💁‍♂️ 🙅‍♀️ 🙅‍♂️ 🙆‍♀️ 🙆‍♂️ 🤷‍♀️ 🤷‍♂️ 🙋‍♀️ 🙋‍♂️ 🤦‍♀️ 🤦‍♂️ 🙎‍♀️ 🙎‍♂️ 🙍‍♀️ 🙍‍♂️ 💇‍♀️ 💇‍♂️ 💆‍♀️ 💆‍♂️ 🤰 🤱 🚶‍♀️ 🚶‍♂️ 🏃‍♀️ 🏃‍♂️ 💃 🕺 👯‍♀️ 👯‍♂️ 👫 👬 👭 💑 👩‍❤️‍👩 👨‍❤️‍👨 💏 👩‍❤️‍💋‍👩 👨‍❤️‍💋‍👨 👪 👨‍👩‍👧 👨‍👩‍👧‍👦 👨‍👩‍👦‍👦 👨‍👩‍👧‍👧 👩‍👩‍👦 👩‍👩‍👧 👩‍👩‍👧‍👦 👩‍👩‍👦‍👦 👩‍👩‍👧‍👧 👨‍👨‍👦 👨‍👨‍👧 👨‍👨‍👧‍👦 👨‍👨‍👦‍👦 👨‍👨‍👧‍👧 👩‍👦 👩‍👧 👩‍👧‍👦 👩‍👦‍👦 👩‍👧‍👧 👨‍👦 👨‍👧 👨‍👧‍👦 👨‍👦‍👦 👨‍👧‍👧 👚 👕 🧥 👖 👔 👗 👙 👘 💄 💋 👣 🧦 👠 👡 👢 👞 👟 🧢 👒 🎩 🎓 👑 ⛑ 🎒 👝 👛 👜 💼 👓 🕶 🧣 🧤 💍 🌂 ☂ ⌚ 📱 📲 💻 ⌨ 🖥 🖨 🖱 🖲 🕹 🗜 💽 💾 💿 📀 📼 📷 📸 📹 🎥 📽 🎞 📞 ☎ 📟 📠 📺 📻 🎙 🎚 🎛 ⏱ ⏲ ⏰ 🕰 ⏳ ⌛ 📡 🔋 🔌 💡 🔦 🕯 🗑 🛢 🛒 💸 💵 💴 💶 💷 💰 💳 💎 ⚖ 🔧 🔨 ⚒ 🛠 ⛏ 🔩 ⚙ ⛓ 🔫 💣 🔪 🗡 ⚔ 🛡 🚬 ⚰ ⚱ 🏺 🔮 📿 💈 ⚗ 🔭 🔬 🕳 💊 💉 🌡 🏷 🔖 🚽 🚿 🛁 🛀 🔑 🗝 🛋 🛌 🛏 🚪 🛎 🖼 🗺 ⛱ 🗿 🛍 🎈 🎏 🎀 🎁 🎊 🎉 🎎 🎐 🏮 ✉ 📩 📨 📧 💌 📮 📪 📫 📬 📭 📦 📯 📥 📤 📜 📃 📑 📊 📈 📉 📄 📅 📆 🗓 📇 🗃 🗳 🗄 📋 🗒 📁 📂 🗂 🗞 📰 📓 📕 📗 📘 📙 📔 📒 📚 📖 🔗 📎 🖇 ✂ 📐 📏 📌 📍 🔐 🔒 🔓 🔏 🖊 🖋 ✒ 📝 ✏ 🖍 🖌 🔍 🔎 🚗 🚕 🚙 🚌 🚎 🏎 🚓 🚑 🚒 🚐 🚚 🚛 🚜 🏍 🛵 🚲 🛴 🚨 🚔 🚍 🚘 🚖 🚡 🚠 🚟 🚃 🚋 🚝 🚄 🚅 🚈 🚞 🚂 🚆 🚇 🚊 🚉 🚁 🛩 ✈ 🛫 🛬 🛶 ⛵ 🛥 🚤 ⛴ 🛳 🚀 🛸 🛰 💺 ⚓ 🚧 ⛽ 🚏 🚦 🚥 🛑 🚢 🎡 🎢 🎠 🏗 🌁 🗼 🏭 ⛲ 🎑 ⛰ 🏔 🗻 🌋 🗾 🏕 ⛺ 🏞 🛣 🛤 🌅 🌄 🏜 🏖 🏝 🌇 🌆 🏙 🌃 🌉 🌌 🌠 🎇 🎆 🌈 🏘 🏰 🏯 🏟 🗽 🏠 🏡 🏚 🏢 🏬 🏣 🏤 🏥 🏦 🏨 🏪 🏫 🏩 💒 🏛 ⛪ 🕌 🕍 🕋 ⛩\"\n",
    "    emoji = emoji_raw.split()\n",
    "   \n",
    "    lista_emoji = []\n",
    "    palavra_limpa = []\n",
    "    \n",
    "    for e in lista:\n",
    "        palavra = ''\n",
    "        for letra in e:\n",
    "            if letra in emoji:\n",
    "                lista_emoji.append(letra)\n",
    "            else:\n",
    "                palavra += letra\n",
    "        palavra_limpa.append(palavra)\n",
    "    Final = lista_emoji + palavra_limpa\n",
    "    return Final "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Função responsável por calcular a probabilidade de uma palavra em uma categoria específica por meio do método de Laplace (smoothing): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Laplace_smoothing (x, cat):\n",
    "   \n",
    "    if cat == 0:\n",
    "        if x in tabela_N:\n",
    "            return (tabela_N[x] + 1) / (N_total + R_total)\n",
    "        else:\n",
    "            return (1) / (N_total + R_total)\n",
    "        \n",
    "    if cat == 1:\n",
    "        if x in tabela_P:\n",
    "            return (tabela_P[x] + 1) / (P_total + R_total)\n",
    "        else:\n",
    "            return (1) / (P_total + R_total)\n",
    "        \n",
    "    if cat == 2:\n",
    "        if x in tabela_NR:\n",
    "            return (tabela_NR[x] + 1) / (NR_total + R_total)\n",
    "        else:\n",
    "            return (1) / (NR_total + R_total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Função responsável por calcular em qual categoria uma tweet tem maior probabilidade de estar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Prob (Tweet):\n",
    "   \n",
    "    P0l = []\n",
    "    P1l = []\n",
    "    P2l = []\n",
    "    P0 = 1\n",
    "    P1 = 1\n",
    "    P2 = 1\n",
    "    \n",
    "    for e in Tweet:\n",
    "        P0l.append(Laplace_smoothing(e,0))\n",
    "        P1l.append(Laplace_smoothing(e,1))\n",
    "        P2l.append(Laplace_smoothing(e,2))\n",
    "    \n",
    "    for e in P0l:\n",
    "        P0 *= e\n",
    "    \n",
    "    for e in P1l:\n",
    "        P1 *= e\n",
    "        \n",
    "    for e in P2l:\n",
    "        P2 *= e\n",
    "    \n",
    "    if P0 > P1 and P0 > P2:\n",
    "        return (0)\n",
    "    \n",
    "    elif P1 > P0 and P1 > P2:\n",
    "        return (1)\n",
    "    \n",
    "    else:\n",
    "        return(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Função responsável por receber os dados a serem classificados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aplica_algoritimo(Tweets):\n",
    "\n",
    "    Tweets_lista = []\n",
    "    Tweet_valor = []\n",
    "\n",
    "    for e in Tweets['Teste']:\n",
    "        Tweets_lista.append(cleanup(e.lower()))\n",
    "    \n",
    "    for e in Tweets_lista:\n",
    "        tweet_split = ajusta_emoji(e.split())\n",
    "        Tweet_valor.append(Prob(tweet_split))\n",
    "    \n",
    "    return Tweet_valor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Aplicando as funções:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fazendo o download do banco de dados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tesla_raw = pd.read_excel (r'Tesla.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separando os Tweets por categoria:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tesla_Negative = Tesla_raw[Tesla_raw[\"Classificação\"] == 0]\n",
    "Tesla_Positive = Tesla_raw[Tesla_raw[\"Classificação\"] == 1]\n",
    "Tesla_NR = Tesla_raw[Tesla_raw[\"Classificação\"] == 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Salvando os tweets como string:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tweets_N_Text = \"\"\n",
    "for e in Tesla_Negative[\"Treinamento\"]:\n",
    "    Tweets_N_Text += e\n",
    "\n",
    "Tweets_P_Text = \"\"\n",
    "for e in Tesla_Positive[\"Treinamento\"]:\n",
    "    Tweets_P_Text += e\n",
    "\n",
    "Tweets_NR_Text = \"\"\n",
    "for e in Tesla_NR[\"Treinamento\"]:\n",
    "    Tweets_NR_Text += e\n",
    "\n",
    "Tweets_R_Text = \"\"\n",
    "for e in Tesla_raw[\"Treinamento\"]:\n",
    "    Tweets_R_Text += e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Limpando as strings por meio da função Cleanup:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tweets_N_TextClean = cleanup(Tweets_N_Text.lower())\n",
    "Tweets_P_TextClean = cleanup(Tweets_P_Text.lower())\n",
    "Tweets_NR_TextClean = cleanup(Tweets_NR_Text.lower())\n",
    "Tweets_R_TextClean = cleanup(Tweets_R_Text.lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separando as palvras e emojis presentes nas strings e salvando eles como Series:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "serie_N = pd.Series(ajusta_emoji(Tweets_N_TextClean.split()))\n",
    "serie_P = pd.Series(ajusta_emoji(Tweets_P_TextClean.split()))\n",
    "serie_NR = pd.Series(ajusta_emoji(Tweets_NR_TextClean.split()))\n",
    "serie_R = pd.Series(ajusta_emoji(Tweets_R_TextClean.split()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparando dados que serão utilizados por funções:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabela_N = serie_N.value_counts()\n",
    "tabela_P = serie_P.value_counts()\n",
    "tabela_NR = serie_NR.value_counts()\n",
    "tabela_R = serie_R.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_total = tabela_N.sum()\n",
    "P_total = tabela_P.sum()\n",
    "NR_total = tabela_NR.sum()\n",
    "R_total = len(tabela_R)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Baixando os tweets de teste e classificando eles:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Teste</th>\n",
       "      <th>Classificação</th>\n",
       "      <th>Classificação do Algoritimo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rt @williamsbob75: another day, another lawsui...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@tesla_truth wait!! they want me to give them ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@davinalexmma @motorcyclebum @tesla you can ge...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rt @melaynalokosky: \"the best service, of cour...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@evnewsdaily i'd happily give my money back to...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>rt @business: teslas have an autopilot functio...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>$tsla - statement of changes in beneficial own...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>rt @insideevs: here's why tesla's h2 2019 will...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>rt @djdura: is there a bug or an extra feature...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>i need that lambo urus in off white and a tesl...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>@brianbrackeen @gerberkawasaki @jason @tesla r...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>rt @bridieev: .@tesla #model3 sales in #austra...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>https://t.co/kux1s3jitt\\n\\nelectric ford f-150...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>rt @itshovah: this is the tesla winner.. nice....</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>@_m_a_r_s_h_y_ @letsrebel1 @drcamiloortiz @kar...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Teste  Classificação  \\\n",
       "0   rt @williamsbob75: another day, another lawsui...              2   \n",
       "1   @tesla_truth wait!! they want me to give them ...              1   \n",
       "2   @davinalexmma @motorcyclebum @tesla you can ge...              1   \n",
       "3   rt @melaynalokosky: \"the best service, of cour...              0   \n",
       "4   @evnewsdaily i'd happily give my money back to...              0   \n",
       "5   rt @business: teslas have an autopilot functio...              0   \n",
       "6   $tsla - statement of changes in beneficial own...              2   \n",
       "7   rt @insideevs: here's why tesla's h2 2019 will...              1   \n",
       "8   rt @djdura: is there a bug or an extra feature...              0   \n",
       "9   i need that lambo urus in off white and a tesl...              1   \n",
       "10  @brianbrackeen @gerberkawasaki @jason @tesla r...              2   \n",
       "11  rt @bridieev: .@tesla #model3 sales in #austra...              1   \n",
       "12  https://t.co/kux1s3jitt\\n\\nelectric ford f-150...              0   \n",
       "13  rt @itshovah: this is the tesla winner.. nice....              1   \n",
       "14  @_m_a_r_s_h_y_ @letsrebel1 @drcamiloortiz @kar...              2   \n",
       "\n",
       "    Classificação do Algoritimo  \n",
       "0                             0  \n",
       "1                             1  \n",
       "2                             2  \n",
       "3                             0  \n",
       "4                             2  \n",
       "5                             0  \n",
       "6                             1  \n",
       "7                             1  \n",
       "8                             1  \n",
       "9                             1  \n",
       "10                            2  \n",
       "11                            1  \n",
       "12                            2  \n",
       "13                            2  \n",
       "14                            2  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Tweet_teste = pd.read_excel (r'Tesla.xlsx', sheet_name = 'Teste', index = False)\n",
    "resultado_teste = aplica_algoritimo(Tweet_teste)\n",
    "Tweet_teste[\"Classificação do Algoritimo\"] = resultado_teste\n",
    "Tweet_teste.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Calculando a porcentagem de acertos:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A porcentagem de acertos é de 58.333333333333336% \n",
      "A porcentagem de verdadeiros negativos é 22.064056939501782% \n",
      "A porcentagem de falsos negativos é 17.437722419928825% \n",
      "A porcentagem de verdadeiros positivos é 32.028469750889684% \n",
      "A porcentagem de falsos positivos é 15.302491103202847% \n",
      "A porcentagem de verdadeiros não relacionados é 8.185053380782918% \n",
      "A porcentagem de falsos não relacionados é 11.743772241992882%\n"
     ]
    }
   ],
   "source": [
    "class_normAL = []\n",
    "for e in Tweet_teste['Classificação do Algoritimo']:\n",
    "             class_normAL.append(e)\n",
    "\n",
    "class_norm = []\n",
    "for e in Tweet_teste['Classificação']:\n",
    "             class_norm.append(e)\n",
    "        \n",
    "i = 0\n",
    "e = 0\n",
    "while i < len(class_norm):\n",
    "    if class_normAL[i] == class_norm[i]:\n",
    "        e += 1\n",
    "    i += 1\n",
    "    \n",
    "cont = 0\n",
    "\n",
    "VN = 0\n",
    "FN = 0\n",
    "VP = 0\n",
    "FP = 0\n",
    "VNR = 0\n",
    "FNR = 0\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "while cont < len(class_norm):\n",
    "    if class_norm[cont] == 0:\n",
    "        if class_normAL[cont] == 0:\n",
    "            VN +=1\n",
    "        else:\n",
    "            FN += 1\n",
    "    \n",
    "    \n",
    "    elif class_norm[cont] == 1:\n",
    "        if class_normAL[cont] == 1:\n",
    "            VP +=1\n",
    "        else:\n",
    "            FP += 1\n",
    "    else:\n",
    "        if class_normAL[cont] == 2:\n",
    "            VNR +=1\n",
    "        else:\n",
    "            FNR += 1\n",
    "   \n",
    "    cont += 1\n",
    "\n",
    "V = VP + FP + FP + FN + VNR + FNR\n",
    "\n",
    "    \n",
    "\n",
    "print(f'A porcentagem de acertos é de {(e/300)*100}% \\nA porcentagem de verdadeiros negativos é {(VN/V)*100}% \\nA porcentagem de falsos negativos é {(FN/V)*100}% \\nA porcentagem de verdadeiros positivos é {(VP/V)*100}% \\nA porcentagem de falsos positivos é {(FP/V)*100}% \\nA porcentagem de verdadeiros não relacionados é {(VNR/V)*100}% \\nA porcentagem de falsos não relacionados é {(FNR/V)*100}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Analisando os resultados:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como pode ser percebido, o percentil de acertos, apesar de não ser muito alto é significante. Isso pode ser depreendido por  meio da comparação com o seguinte valor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.443333\n",
       "0    0.370000\n",
       "2    0.186667\n",
       "Name: Classificação, dtype: float64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Tweet_teste['Classificação'].value_counts(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sendo a taxa de acertos superior ao maior percentil acima, que representa a densidade da distribuição da coluna manualmente preenchida na avalição dos tweets usados como teste, isso demonstra que o código foi capaz de acertar a classificação de uma quantidade considerável de mensagens.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vale notar também que em todas as categorias, com exceção da \"não relacionados\", a porcentagem de verdadeiros foi maior. Dessa forma, um aumento da base de treinamento para essa categoria poderia auxiliar no crescimento do indice de verdadeiros não relacionados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classificador utilazando o processo de stemming:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O processo de steemming consiste na transformação de verbos conjugados ou flexionados em sua formatação mais simples. Dessa forma, o banco de dados utilizado para classificação de tweets tende a ficar mais conciso mas mais importante, tende a fazer com que o código produza resultados mais expressivos em termos de porcentagem de acertos. A justificativa para tanto, se dá na maior quantidade de palvras repetidas em um dado grupo, o que no método de Laplace (smoothing) implica numa maior probilidade de uma dada palavra, que também se encontra no banco de dados, estar nesse grupo. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Novas funções utilizadas:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Função responsável por calcular a probabilidade de uma palavra em uma categoria específica por meio do método de Laplace (smoothing):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Laplace_smoothingS (x, cat):\n",
    "   \n",
    "    if cat == 0:\n",
    "        if x in tabela_NS:\n",
    "            return (tabela_NS[x] + 1) / (N_totalS + R_totalS)\n",
    "        else:\n",
    "            return (1) / (N_totalS + R_totalS)\n",
    "        \n",
    "    if cat == 1:\n",
    "        if x in tabela_PS:\n",
    "            return (tabela_PS[x] + 1) / (P_totalS + R_totalS)\n",
    "        else:\n",
    "            return (1) / (P_totalS + R_totalS)\n",
    "        \n",
    "    if cat == 2:\n",
    "        if x in tabela_NRS:\n",
    "            return (tabela_NRS[x] + 1) / (NR_totalS + R_totalS)\n",
    "        else:\n",
    "            return (1) / (NR_totalS + R_totalS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Função responsável por calcular em qual categoria uma tweet tem maior probabilidade de estar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ProbS (Tweet):\n",
    "   \n",
    "    P0l = []\n",
    "    P1l = []\n",
    "    P2l = []\n",
    "    P0 = 1\n",
    "    P1 = 1\n",
    "    P2 = 1\n",
    "    \n",
    "    for e in Tweet:\n",
    "        P0l.append(Laplace_smoothingS(stemmer.stem(e),0))\n",
    "        P1l.append(Laplace_smoothingS(stemmer.stem(e),1))\n",
    "        P2l.append(Laplace_smoothingS(stemmer.stem(e),2))\n",
    "    \n",
    "    for e in P0l:\n",
    "        P0 *= e\n",
    "    \n",
    "    for e in P1l:\n",
    "        P1 *= e\n",
    "        \n",
    "    for e in P2l:\n",
    "        P2 *= e\n",
    "    \n",
    "    if P0 > P1 and P0 > P2:\n",
    "        return (0)\n",
    "    \n",
    "    elif P1 > P0 and P1 > P2:\n",
    "        return (1)\n",
    "    \n",
    "    else:\n",
    "        return(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Função responsável por receber os dados a serem classificados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aplica_algoritimoS(Tweets):\n",
    "    \n",
    "    Tweets_lista = []\n",
    "    Tweet_valor = []\n",
    "\n",
    "    for e in Tweets['Teste']:\n",
    "        Tweets_lista.append(cleanup(e.lower()))\n",
    "    \n",
    "    for e in Tweets_lista:\n",
    "        tweet_split = ajusta_emoji(e.split())\n",
    "        Tweet_valor.append(ProbS(tweet_split))\n",
    "    \n",
    "    return Tweet_valor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Aplicando as funções:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Salvando as palvras das strings em um lista:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "NCP = (Tweets_N_TextClean.split())\n",
    "PCP = (Tweets_P_TextClean.split())\n",
    "NRCP = (Tweets_NR_TextClean.split())\n",
    "RCP = (Tweets_R_TextClean.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aplicando o processo de stemming para cada palavra em cada uma das categorias:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_N = []\n",
    "for e in NCP:\n",
    "    j = stemmer.stem(e)\n",
    "    lista_N.append(j)\n",
    "    \n",
    "\n",
    "lista_P = []\n",
    "for e in PCP:\n",
    "    j = stemmer.stem(e)\n",
    "    lista_P.append(j)\n",
    "\n",
    "\n",
    "lista_NR = []\n",
    "for e in NRCP:\n",
    "    j = stemmer.stem(e)\n",
    "    lista_NR.append(j)\n",
    "\n",
    "lista_R = []\n",
    "for e in RCP:\n",
    "    j = stemmer.stem(e)\n",
    "    lista_R.append(j)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "salvando as listas como Series e separando os emojis: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "serie_NS = pd.Series(ajusta_emoji(lista_N))\n",
    "serie_PS = pd.Series(ajusta_emoji(lista_P))\n",
    "serie_NRS = pd.Series(ajusta_emoji(lista_NR))\n",
    "serie_RS = pd.Series(ajusta_emoji(lista_R))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparando dados que serão utilizados por funções:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabela_NS = serie_NS.value_counts()\n",
    "tabela_PS = serie_PS.value_counts()\n",
    "tabela_NRS = serie_NRS.value_counts()\n",
    "tabela_RS = serie_RS.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_totalS = tabela_NS.sum()\n",
    "P_totalS = tabela_PS.sum()\n",
    "NR_totalS = tabela_NRS.sum()\n",
    "R_totalS = len(tabela_RS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Baixando os tweets de teste e classificando eles:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Teste</th>\n",
       "      <th>Classificação</th>\n",
       "      <th>Classificação do Algoritimo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rt @williamsbob75: another day, another lawsui...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@tesla_truth wait!! they want me to give them ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@davinalexmma @motorcyclebum @tesla you can ge...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rt @melaynalokosky: \"the best service, of cour...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@evnewsdaily i'd happily give my money back to...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>rt @business: teslas have an autopilot functio...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>$tsla - statement of changes in beneficial own...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>rt @insideevs: here's why tesla's h2 2019 will...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>rt @djdura: is there a bug or an extra feature...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>i need that lambo urus in off white and a tesl...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>@brianbrackeen @gerberkawasaki @jason @tesla r...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>rt @bridieev: .@tesla #model3 sales in #austra...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>https://t.co/kux1s3jitt\\n\\nelectric ford f-150...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>rt @itshovah: this is the tesla winner.. nice....</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>@_m_a_r_s_h_y_ @letsrebel1 @drcamiloortiz @kar...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Teste  Classificação  \\\n",
       "0   rt @williamsbob75: another day, another lawsui...              2   \n",
       "1   @tesla_truth wait!! they want me to give them ...              1   \n",
       "2   @davinalexmma @motorcyclebum @tesla you can ge...              1   \n",
       "3   rt @melaynalokosky: \"the best service, of cour...              0   \n",
       "4   @evnewsdaily i'd happily give my money back to...              0   \n",
       "5   rt @business: teslas have an autopilot functio...              0   \n",
       "6   $tsla - statement of changes in beneficial own...              2   \n",
       "7   rt @insideevs: here's why tesla's h2 2019 will...              1   \n",
       "8   rt @djdura: is there a bug or an extra feature...              0   \n",
       "9   i need that lambo urus in off white and a tesl...              1   \n",
       "10  @brianbrackeen @gerberkawasaki @jason @tesla r...              2   \n",
       "11  rt @bridieev: .@tesla #model3 sales in #austra...              1   \n",
       "12  https://t.co/kux1s3jitt\\n\\nelectric ford f-150...              0   \n",
       "13  rt @itshovah: this is the tesla winner.. nice....              1   \n",
       "14  @_m_a_r_s_h_y_ @letsrebel1 @drcamiloortiz @kar...              2   \n",
       "\n",
       "    Classificação do Algoritimo  \n",
       "0                             1  \n",
       "1                             1  \n",
       "2                             1  \n",
       "3                             0  \n",
       "4                             2  \n",
       "5                             0  \n",
       "6                             1  \n",
       "7                             1  \n",
       "8                             0  \n",
       "9                             1  \n",
       "10                            2  \n",
       "11                            1  \n",
       "12                            2  \n",
       "13                            2  \n",
       "14                            2  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Tweet_testeS = pd.read_excel (r'Tesla.xlsx', sheet_name = 'Teste', index = False)\n",
    "resultado_testeS = aplica_algoritimoS(Tweet_testeS)\n",
    "Tweet_testeS[\"Classificação do Algoritimo\"] = resultado_testeS\n",
    "Tweet_testeS.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Calculando a porcentagem de acertos:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A porcentagem de acertos é de 57.99999999999999% \n",
      "A porcentagem de verdadeiros negativos é 21.70818505338078% \n",
      "A porcentagem de falsos negativos é 17.793594306049823% \n",
      "A porcentagem de verdadeiros positivos é 32.38434163701068% \n",
      "A porcentagem de falsos positivos é 14.94661921708185% \n",
      "A porcentagem de verdadeiros não relacionados é 7.829181494661921% \n",
      "A porcentagem de falsos não relacionados é 12.099644128113878%\n"
     ]
    }
   ],
   "source": [
    "class_SAL = []\n",
    "for e in Tweet_testeS['Classificação do Algoritimo']:\n",
    "             class_SAL.append(e)\n",
    "\n",
    "class_S = []\n",
    "for e in Tweet_testeS['Classificação']:\n",
    "             class_S.append(e)\n",
    "\n",
    "i = 0\n",
    "e = 0\n",
    "while i < len(class_norm):\n",
    "    if class_SAL[i] == class_S[i]:\n",
    "        e += 1\n",
    "    i += 1\n",
    "\n",
    "cont = 0\n",
    "\n",
    "VN = 0\n",
    "FN = 0\n",
    "VP = 0\n",
    "FP = 0\n",
    "VNR = 0\n",
    "FNR = 0\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "while cont < len(class_norm):\n",
    "    if class_S[cont] == 0:\n",
    "        if class_SAL[cont] == 0:\n",
    "            VN +=1\n",
    "        else:\n",
    "            FN += 1\n",
    "    \n",
    "    \n",
    "    elif class_S[cont] == 1:\n",
    "        if class_SAL[cont] == 1:\n",
    "            VP +=1\n",
    "        else:\n",
    "            FP += 1\n",
    "    else:\n",
    "        if class_SAL[cont] == 2:\n",
    "            VNR +=1\n",
    "        else:\n",
    "            FNR += 1\n",
    "   \n",
    "    cont += 1\n",
    "\n",
    "V = VP + FP + FP + FN + VNR + FNR\n",
    "\n",
    "    \n",
    "\n",
    "print(f'A porcentagem de acertos é de {(e/300)*100}% \\nA porcentagem de verdadeiros negativos é {(VN/V)*100}% \\nA porcentagem de falsos negativos é {(FN/V)*100}% \\nA porcentagem de verdadeiros positivos é {(VP/V)*100}% \\nA porcentagem de falsos positivos é {(FP/V)*100}% \\nA porcentagem de verdadeiros não relacionados é {(VNR/V)*100}% \\nA porcentagem de falsos não relacionados é {(FNR/V)*100}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como pode ser percebido, ao contrário do que se era esperado, o processo de stemming implicou numa redução no índice de acerto do código. Uma possível explicação para tal fenômeno é a caracterização dos tweets, os quais são dependentes da conjugação ou mesmo da flexão verbal. Em outras palavras, o modo com que um verbo é conjugado ou flexionado é um indicativo considerável na classificação dos tweets em classes, ou seja, quando se utuliza o processo de stemming, o índice de acerto tende a cair."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Implementando a função em tempo real:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importando as bibliotecas a serem utlizadas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "#Instalando o tweepy\n",
    "!pip install tweepy\n",
    "\n",
    "import time\n",
    "import tweepy\n",
    "import math\n",
    "import os.path\n",
    "import pandas as pd\n",
    "import json\n",
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Função responsável por receber os dados a serem classificados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aplica_algoritimoSF(Tweets):\n",
    "    \n",
    "    Tweets_lista = []\n",
    "    Tweet_valor = []\n",
    "\n",
    "    for e in Tweets:\n",
    "        Tweets_lista.append(cleanup(e.lower()))\n",
    "    \n",
    "    for e in Tweets_lista:\n",
    "        tweet_split = ajusta_emoji(e.split())\n",
    "        Tweet_valor.append(ProbS(tweet_split))\n",
    "    \n",
    "    return Tweet_valor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Função que faz os tweets serem baixados a cada 30 segundos e os classifica:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                Tweet  Classificação\n",
      "0   @mtass7 is it true @forbrukertilsyn &amp; @elo...              1\n",
      "1   @andrewbkin @blairqualey @ncda_bc @cevforbc @t...              2\n",
      "2   rt @roshennn: the reason i compared it to tesl...              1\n",
      "3   rt @elonmusknewsorg: tesla model s plaid varia...              1\n",
      "4   @evasrebecca not at all i'm a big champion of ...              0\n",
      "5   hey, i'm eating apple sauce out of some sort o...              2\n",
      "6   @tesla_truth because it means leaving their co...              1\n",
      "7   rt @gwestr: flashback 1 year, tesla was \"strug...              1\n",
      "8   rt @kerooke: 20,000km (12,000+ miles)\\n45 days...              2\n",
      "9   rt @roadshow: hang on tesla, porsche may have ...              0\n",
      "10  rt @tppf: \"one of those catastrophic effects w...              1\n",
      "11  @antonio1sn @jimmyjonestheg1 @mmike2016 @natel...              2\n",
      "12  rt @vincent13031925: deutsche bank posts bulli...              2\n",
      "13  @boblokerse @lidlgb @pod_point :-) we have a 2...              1\n",
      "14  @kimpaquette @elonmusk @28delayslater @tesla t...              1\n",
      " \n",
      "A porcentagem de tweet negativos é de 13.333333333333334% \n",
      "A porcentagem de tweet positivos é de 53.333333333333336% \n",
      "A porcentagem de tweet não relacionados é de 33.33333333333333%\n",
      "\n",
      "                                                Tweet  Classificação\n",
      "0   @manuelpazosmsx @tesla @elonmusk @teslarati my...              1\n",
      "1   rt @kerooke: 20,000km (12,000+ miles)\\n45 days...              2\n",
      "2   @antonio1sn @jimmyjonestheg1 @mmike2016 @natel...              2\n",
      "3   rt @roadshow: hang on tesla, porsche may have ...              0\n",
      "4   rt @quot3bot: \"if you only knew the magnificen...              1\n",
      "5   @tesla_truth because it means leaving their co...              1\n",
      "6   rt @gwestr: flashback 1 year, tesla was \"strug...              1\n",
      "7   hey, i'm eating apple sauce out of some sort o...              2\n",
      "8   @evasrebecca not at all i'm a big champion of ...              0\n",
      "9   rt @jxyerxd: to the student who drives a tesla...              1\n",
      "10  @kimpaquette @elonmusk @28delayslater @tesla t...              1\n",
      "11  rt @pluginfud: boomers take note https://t.co/...              1\n",
      "12  rt @roshennn: the reason i compared it to tesl...              1\n",
      "13  @boblokerse @lidlgb @pod_point :-) we have a 2...              1\n",
      "14  i take pride in knowing that i basically paid ...              1\n",
      " \n",
      "A porcentagem de tweet negativos é de 13.333333333333334% \n",
      "A porcentagem de tweet positivos é de 66.66666666666666% \n",
      "A porcentagem de tweet não relacionados é de 20.0%\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-49-8b644cdc37c0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[1;32mwhile\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m200\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 69\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'{printit()}\\n'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-49-8b644cdc37c0>\u001b[0m in \u001b[0;36mprintit\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mprintit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'auth.pass'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfp\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def printit():\n",
    "    \n",
    "    time.sleep(30)\n",
    "    \n",
    "    with open('auth.pass') as fp:    \n",
    "        data = json.load(fp)\n",
    "        \n",
    "\n",
    "    auth = tweepy.OAuthHandler(data['consumer_key'], data['consumer_secret'])\n",
    "    auth.set_access_token(data['access_token'], data['access_token_secret'])\n",
    "\n",
    "\n",
    "    produto = 'Tesla'\n",
    "    n = 500\n",
    "    t = 450\n",
    "    lang = 'en'\n",
    "    \n",
    "    api = tweepy.API(auth)\n",
    "    msgs = []\n",
    "    msg_final=[]\n",
    "\n",
    "\n",
    "    for msg in tweepy.Cursor(api.search, q=produto, lang=lang).items():  \n",
    "        msgs.append(msg.text.lower())\n",
    "        if len(msgs) > 30:\n",
    "            break\n",
    "    msg_final = set(msgs)\n",
    "    \n",
    "    Final = []\n",
    "    i = 0\n",
    "    for e in msg_final:\n",
    "        Final.append(e)\n",
    "        if len (Final) >= 15:\n",
    "            break\n",
    "\n",
    "    shuffle(Final)\n",
    "     \n",
    "    Tweet = Final  \n",
    "    valor = aplica_algoritimoSF(Final)\n",
    "    \n",
    "    list_of_tuples = list(zip(Tweet, valor)) \n",
    "    list_of_tuples   \n",
    "    df = pd.DataFrame(list_of_tuples, columns = ['Tweet', 'Classificação'])\n",
    "    \n",
    "    L0 = 0\n",
    "    L1 = 0\n",
    "    L2 = 0\n",
    "    \n",
    "    for e in df['Classificação']:\n",
    "         \n",
    "        if e == 0:\n",
    "            L0+=1\n",
    "            \n",
    "        if e == 1:\n",
    "            L1+=1\n",
    "            \n",
    "        if e == 2:\n",
    "            L2+=1\n",
    "    \n",
    "    P0 = (L0/15)*100\n",
    "    P1 = (L1/15)*100\n",
    "    P2 = (L2/15)*100\n",
    "    \n",
    "    return (f'{df}\\n \\nA porcentagem de tweet negativos é de {P0}% \\nA porcentagem de tweet positivos é de {P1}% \\nA porcentagem de tweet não relacionados é de {P2}%')\n",
    "\n",
    "n = 1\n",
    "\n",
    "while (n < 200):\n",
    "    print(f'{printit()}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como pode ser observado o código é capaz de classificar até 15 tweets a cada 30 segundos, informando em termos de porcentagem a quantidade de tweets positivos, negativos e que não possuem relação com a empresa. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusão:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Em suma, o classificador se mostrou eficiente, podendo prever com certa acurácia a categoria de determinados tweets. Para aumentar a quantidade de acertos do código, pode-se empregar os tweets de teste classificados de forma incorreta no banco de dados (Treinamento). \n",
    "\n",
    "As aplicações para esse tipo de classificador são muitas, que variam de fins empresariais, como a avaliação de empresa, até mesmo para fins de entretenimento, como o que ocorreu durante a copa do mundo, quando empresas foram contratadas para avaliar o que estava sendo dito sobre determinados jogadores de futebol, o que mostra a importância desse modelo de classificação."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
